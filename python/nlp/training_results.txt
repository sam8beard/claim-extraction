("('SOURCE', 'European Parliamentary Research Service Scientific Foresight "
 "Unit')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'Eleanor Bird')\n\n"
"('SOURCE', 'Jasmin Fox-Skelly')\n\n"
"('SOURCE', 'Ruth Larbey')\n\n"
"('SOURCE', 'Emma Weitkamp')\n\n"
"('SOURCE', 'Alan Winfield')\n\n"
"('SOURCE', 'the Science Communication Unit')\n\n"
"('SOURCE', 'John C. Havens')\n\n"
("('SOURCE', 'The IEEE Global Initiative on Ethics of Autonomous and "
 "Intelligent Systems')\n"
 '\n')
"('SOURCE', 'Jack Stilgoe')\n\n"
"('SOURCE', 'Mihalis Kritikos')\n\n"
"('SOURCE', 'the European Parliament')\n\n"
"('SOURCE', 'the European Parliament')\n\n"
'(\'SOURCE\', "the European Commission\'s")\n\n'
"('SOURCE', 'Panel for the Future of Science and Technology II')\n\n"
("('CLAIM_CONTENTS', 'the question of personhood, and whether AI systems "
 "should have moral agency')\n"
 '\n')
"('CLAIM_VERB', 'argues')\n\n"
("('CLAIM_CONTENTS', 'that, although markets are suited to automation, there "
 'are risks including the use of AI for intentional market manipulation and '
 "collusion')\n"
 '\n')
"('CLAIM_VERB', 'held')\n\n"
("('CLAIM_CONTENTS', 'liable themselves, they do raise questions about who is "
 'liable for which crime (or indeed if human agents can avoid liability by '
 "claiming they did not know the AI could or would do such a thing)')\n"
 '\n')
"('CLAIM_VERB', 'ways')\n\n"
("('CLAIM_CONTENTS', 'that build trust and understanding, and respect human "
 "and civil rights')\n"
 '\n')
"('CLAIM_VERB', 'arguing')\n\n"
("('CLAIM_CONTENTS', 'that AI must not affect basic and fundamental human "
 "rights')\n"
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'recommends')\n\n"
("('CLAIM_CONTENTS', 'governance frameworks, standards and regulatory bodies "
 'to oversee use of AI and ensure that human well-being is prioritised '
 "throughout the design phase')\n"
 '\n')
"('SOURCE', 'The Montreal Protocol')\n\n"
"('CLAIM_VERB', 'argues')\n\n"
("('CLAIM_CONTENTS', 'that AI should encourage and support the growth and "
 "flourishing of human well-being')\n"
 '\n')
("('CLAIM_CONTENTS', 'that nudging requires particular ethical "
 "consideration')\n"
 '\n')
"('CLAIM_VERB', 'auditable')\n\n"
("('CLAIM_CONTENTS', 'as a means of ensuring that manufacturers, designers and "
 "owners/operators of AI can be held responsible for harm caused')\n"
 '\n')
"('CLAIM_VERB', 'recognition')\n\n"
"('CLAIM_VERB', 'assessed')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
("('CLAIM_CONTENTS', 'that AI must be safe, trustworthy, reliable and act with "
 "integrity')\n"
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'suggests')\n\n"
"('SOURCE', 'the Japanese Society for AI')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'arguing')\n\n"
('(\'CLAIM_CONTENTS\', "that AI should not be granted the status of '
 "'personhood' and that existing laws should be scrutinised to ensure that "
 'they do not practically give AI legal autonomy")\n'
 '\n')
"('SOURCE', 'The UNI Global Union')\n\n"
"('CLAIM_VERB', 'states')\n\n"
("('CLAIM_CONTENTS', 'that AI should put people and plants first, striving to "
 "protect and enhance biodiversity and ecosystems.')\n"
 '\n')
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'a range of ways in which this could be achieved, as a "
 'way of raising a number of topics that should be addressed through such '
 "initiatives')\n"
 '\n')
"('CLAIM_VERB', 'raises')\n\n"
"('CLAIM_VERB', 'associated')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology IV')\n\n"
"('CLAIM_VERB', 'technologies')\n\n"
"('CLAIM_CONTENTS', 'that warrant consideration.')\n\n"
("('CLAIM_CONTENTS', 'that both physical and emotional hazards should be "
 "balanced against expected benefits to the user.')\n"
 '\n')
"('SOURCE', 'Sweden')\n\n"
"('SOURCE', 'The United Nations')\n\n"
"('SOURCE', 'UNICRI Centre for AI and Robotics')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology VI')\n\n"
"('SOURCE', 'EU')\n\n"
('(\'SOURCE\', "The European Commission\'s Communication on Artificial '
 'Intelligence")\n'
 '\n')
"('CLAIM_VERB', 'survey')\n\n"
('(\'CLAIM_CONTENTS\', "a wide range of informal definitions of intelligence, '
 "identifying three common features: that intelligence is (1) 'a property that "
 'an individual agent has as it interacts with its environment or '
 "environments', (2) 'related to the agent's ability to succeed or profit with "
 "respect to some goal or objective', and (3) 'depends on how able that agent "
 'is to adapt to different objectives and environments\'.")\n'
 '\n')
("('CLAIM_CONTENTS', 'that gives rise to almost all of the ethical issues "
 "surveyed in this report')\n"
 '\n')
"('CLAIM_VERB', 'reflects')\n\n"
("('CLAIM_CONTENTS', 'that fact that current AIs and robots are typically only "
 "capable of undertaking one specialised task.')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology 2')\n\n"
("('CLAIM_CONTENTS', 'that present-day narrow AI is often better than most "
 'humans at one particular task; examples are chess- or Go-playing AIs, search '
 "engines or natural language translation systems')\n"
 '\n')
"('SOURCE', 'ANN')\n\n"
"('SOURCE', 'ANN')\n\n"
"('CLAIM_VERB', 'backgrounds')\n\n"
"('SOURCE', 'ANN')\n\n"
"('CLAIM_VERB', 'backgrounds')\n\n"
"('CLAIM_CONTENTS', 'as wolves, rather than the wolf itself')\n\n"
("('CLAIM_CONTENTS', 'the limitation that it is generally very slow (compared "
 "with humans who can often learn from as few as one trial')\n"
 '\n')
"('SOURCE', 'Kant')\n\n"
"('SOURCE', 'the British Standards Institute')\n\n"
"('CLAIM_VERB', 'perpetuate')\n\n"
("('CLAIM_CONTENTS', 'the biases, intended or otherwise, of existing social "
 "systems or their creators')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology 4')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('CLAIM_VERB', 'presents')\n\n"
("('CLAIM_CONTENTS', 'the current status of AI Ethical standards and "
 "regulation')\n"
 '\n')
"('SOURCE', 'British Standard BS8611')\n\n"
"('SOURCE', 'IEEE')\n\n"
("('CLAIM_CONTENTS', 'developing a number of standards that affect AI in a "
 "range of contexts')\n"
 '\n')
"('SOURCE', 'the Future of Life Institute')\n\n"
"('CLAIM_VERB', 'holds')\n\n"
('(\'CLAIM_CONTENTS\', "great economic, social, medical, security, and '
 "environmental promise', with potential benefits including: Helping people to "
 'acquire new skills and training;Democratising services;Designing and '
 'delivering faster production times and quicker iteration cycles;Reducing '
 'energy usage;Providing real-time environmental monitoring for air pollution '
 'and quality;Enhancing cybersecurity defences;Boosting national '
 'output;Reducing healthcare inefficiencies;Creating new kinds of enjoyable '
 'experiences and interactions for people; andImproving real-time translation '
 'services to connect people across the globe")\n'
 '\n')
"('CLAIM_VERB', 'summarises')\n\n"
("('CLAIM_CONTENTS', 'the main ethical, social and legal considerations in the "
 'deployment STOA | Panel for the Future of Science and Technology 6 of AI, '
 "drawing insights from relevant academic literature.')\n"
 '\n')
"('CLAIM_VERB', 'added')\n\n"
("('CLAIM_CONTENTS', 'that robots, AI and sensors will have on the workforce "
 "because we are in the early stages of the technology revolution.')\n"
 '\n')
"('CLAIM_VERB', 'believed')\n\n"
('(\'CLAIM_CONTENTS\', "that robots and digital agents would displace '
 "significant numbers of both 'blue' and 'white' collar workers, with many "
 'expressing concern that this would lead to vast increases in income '
 'inequality, large numbers of unemployable people, and breakdowns in the '
 'social order (Smith and Anderson, 2014")\n'
 '\n')
"('CLAIM_VERB', 'expected')\n\n"
("('CLAIM_CONTENTS', 'that technology would not displace more jobs than it "
 "created by 2025')\n"
 '\n')
"('CLAIM_VERB', 'argue')\n\n"
('(\'CLAIM_CONTENTS\', "that technology is already producing major changes in '
 "the workforce: 'Technological progress is going to leave behind some people, "
 "perhaps even a lot of people, as it races ahead… there's never been a better "
 'time to be a worker with special skills or the right education because these '
 'people can use technology to create and capture value.")\n'
 '\n')
"('SOURCE', 'Brynjolfsson')\n\n"
"('SOURCE', 'McAfee')\n\n"
"('SOURCE', 'Ford')\n\n"
"('CLAIM_VERB', 'argues')\n\n"
('(\'CLAIM_CONTENTS\', "that: \'as technology accelerates, machine automation '
 'may ultimately penetrate the economy to the extent that wages no longer '
 'provide the bulk of consumers with adequate discretionary income and '
 'confidence in the future")\n'
 '\n')
"('CLAIM_VERB', 'warns')\n\n"
('(\'CLAIM_CONTENTS\', "that \'at some point in the future — it might be many '
 'years or decades from now — machines will be able to do the jobs of a large '
 "percentage of the 'average' people in our population, and these people will "
 'not be able to find new jobs")\n'
 '\n')
"('CLAIM_VERB', 'ways')\n\n"
"('CLAIM_CONTENTS', 'that are not directly linked to technology')\n\n"
"('CLAIM_VERB', 'calculate')\n\n"
("('CLAIM_CONTENTS', 'that there is a high probability that 47 percent of U.S. "
 "workers will see their jobs become automated over the next 20 years')\n"
 '\n')
"('CLAIM_VERB', 'specialists')\n\n"
"('CLAIM_VERB', 'predicted')\n\n"
"('SOURCE', 'STOA')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
("('CLAIM_CONTENTS', '30,000 a year, yet their roles are not thought to be "
 "amenable to automation.')\n"
 '\n')
"('CLAIM_VERB', 'fields')\n\n"
"('SOURCE', 'the U.S. Department of Education')\n\n"
"('SOURCE', 'STEM')\n\n"
"('SOURCE', 'Robinson')\n\n"
"('SOURCE', 'EU')\n\n"
"('CLAIM_VERB', 'patterns')\n\n"
("('CLAIM_CONTENTS', 'highlight a key area of concern in the increasing "
 'development and implementation of AI if nobody is to be disadvantaged or '
 "left behind (European Commission, 2017')\n"
 '\n')
"('SOURCE', 'John Havens')\n\n"
"('SOURCE', 'Jack Stilgoe')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
("('CLAIM_CONTENTS', 'that this will come at the expense of their human "
 "workforces')\n"
 '\n')
"('CLAIM_VERB', 'mean')\n\n"
"('SOURCE', 'Winfield')\n\n"
"('CLAIM_VERB', 'states')\n\n"
('(\'CLAIM_CONTENTS\', "that new jobs may require highly skilled workers but '
 "be repetitive and dull, creating 'white-collar sweatshops' filled with "
 'workers performing tasks such as tagging and moderating content")\n'
 '\n')
"('CLAIM_VERB', 'automaton')\n\n"
("('CLAIM_CONTENTS', 'that was revealed to be operated by a human chess master "
 "hidden inside the cabinet')\n"
 '\n')
"('SOURCE', 'Gray')\n\n"
"('SOURCE', 'Suri')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
('(\'CLAIM_CONTENTS\', "that 20 million individuals are now employed '
 "worldwide, via third party contractors, in an on-demand 'gig economy', "
 'working outside the protection of labour laws")\n'
 '\n')
"('SOURCE', 'work3')\n\n"
"('SOURCE', 'Harvard')\n\n"
"('SOURCE', 'Mary L. Gray')\n\n"
"('SOURCE', 'Gray')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'Kenya')\n\n"
"('SOURCE', 'Roberts')\n\n"
"('SOURCE', 'Chen')\n\n"
"('CLAIM_VERB', 'advises')\n\n"
('(\'CLAIM_CONTENTS\', "that the economic, social and psychological impacts of '
 '\'ghost work\' should be dealt with systematically")\n'
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'The Future of Life Institute')\n\n"
"('SOURCE', 'The White House')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'The Future of Life Institute')\n\n"
"('CLAIM_VERB', 'states')\n\n"
("('CLAIM_CONTENTS', 'that AI may be capable of tackling a number of the most "
 'difficult global issues – poverty, disease, conflict – and thus improve '
 "countless lives.')\n"
 '\n')
"('CLAIM_VERB', 'highlights')\n\n"
("('CLAIM_CONTENTS', 'the importance of ensuring that potential benefits of AI "
 'do not accumulate unequally, and are made accessible to as many people as '
 "possible.')\n"
 '\n')
"('CLAIM_VERB', 'states')\n\n"
('(\'CLAIM_CONTENTS\', "that innovation and technological change \'does not '
 "happen in a vacuum': the future of AI may be shaped not by technological "
 'capability, but by a wide range of non-technical incentives (The White '
 'House, 2016")\n'
 '\n')
"('SOURCE', 'Conn')\n\n"
("('CLAIM_CONTENTS', 'a need for inventors to consider the wider potential "
 "impacts of their creations.')\n"
 '\n')
"('SOURCE', 'Duckworth')\n\n"
"('SOURCE', 'Bryson')\n\n"
"('CLAIM_VERB', 'mention')\n\n"
"('SOURCE', 'Conn')\n\n"
"('SOURCE', 'Bryson')\n\n"
"('CLAIM_VERB', 'agree')\n\n"
('(\'CLAIM_CONTENTS\', "with this call for policy and regulation, stating that '
 "'it is not sufficient to fund basic research and expect it to be widely and "
 'equitably diffused in society by private actors")\n'
 '\n')
"('SOURCE', 'Servoz')\n\n"
"('SOURCE', 'The Future of Life Institute')\n\n"
"('CLAIM_VERB', 'lists')\n\n"
('(\'CLAIM_CONTENTS\', "a number of policy recommendations to tackle the '
 "possible 'economic impacts, labour shifts, inequality, technological "
 'unemployment\', and social and political tensions that may accompany AI")\n'
 '\n')
"('SOURCE', 'Institute')\n\n"
"('CLAIM_VERB', 'suggests')\n\n"
('(\'CLAIM_CONTENTS\', "that policies should focus on those most at risk of '
 'being left behind – caregivers, women and girls, underrepresented '
 'populations and the vulnerable – and on those building AI systems, to target '
 "any 'skewed product design, blind spots, false assumptions [and] value "
 "systems and goals encoded into machines' (The Future of Life Institute, "
 'n.d")\n'
 '\n')
"('SOURCE', 'Bryson')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
('(\'CLAIM_CONTENTS\', "that governments seek to improve The ethics of '
 'artificial intelligence: Issues and initiatives 11 their related knowledge '
 'and rely more on experts; that relevant research is allocated more funding; '
 "that policymakers plan for the future, seeking 'robustness and preparedness "
 "in the face of uncertainty'; and that AI is widely applied and proactively "
 'made accessible (especially in areas of great social value, such as poverty, '
 'illness, or clean energy")\n'
 '\n')
"('SOURCE', 'Wolfe')\n\n"
"('SOURCE', 'Gagan')\n\n"
"('SOURCE', 'Jacobs')\n\n"
"('SOURCE', 'Jacobs')\n\n"
"('CLAIM_VERB', 'discusses')\n\n"
('(\'CLAIM_CONTENTS\', "the potential for \'prosumers\' (those who both '
 'produce and consume energy, interacting with the grid in a new way) to help '
 "decentralise energy production and be a 'positive disruptive force' in the "
 'electricity industry – if energy strategy is regulated effectively via '
 'updated policy and management")\n'
 '\n')
"('SOURCE', 'Ramchurn')\n\n"
"('SOURCE', 'Jack Stilgoe')\n\n"
"('SOURCE', 'Nemitz')\n\n"
"('CLAIM_VERB', 'writes')\n\n"
('(\'CLAIM_CONTENTS\', "that it would be \'naive\' to ignore that AI will '
 "concentrate power in the hands of a few digital internet giants, as 'the "
 'reality of how [most societies] use the Internet and what the Internet '
 'delivers to them is shaped by a few mega corporations…the development of AI '
 'is dominated exactly by these mega corporations and their dependent '
 'ecosystems")\n'
 '\n')
"('SOURCE', 'Microsoft')\n\n"
"('SOURCE', 'Apple')\n\n"
"('SOURCE', 'Nemitz')\n\n"
"('SOURCE', 'Google')\n\n"
"('SOURCE', 'Google')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'Nemitz')\n\n"
"('CLAIM_VERB', 'concludes')\n\n"
('(\'CLAIM_CONTENTS\', "that \'this accumulation of power in the hands of a '
 'few — the power of money, the power over infrastructures for democracy and '
 'discourse, the power over individuals based on profiling and the dominance '
 'in AI innovation…must be seen together, and…must inform the present debate '
 'about ethics and law for AI\'")\n'
 '\n')
"('SOURCE', 'Bryson')\n\n"
"('CLAIM_VERB', 'believes')\n\n"
("('CLAIM_CONTENTS', 'this concentration of power could be an inevitable "
 "consequence of the falling costs of robotic technology')\n"
 '\n')
"('CLAIM_VERB', 'maintain')\n\n"
"('SOURCE', 'Bryson')\n\n"
"('CLAIM_VERB', 'notes')\n\n"
("('CLAIM_CONTENTS', 'that the rise of AI could lead to wealth inequality and "
 "political upheaval')\n"
 '\n')
"('SOURCE', 'McCarty')\n\n"
"('SOURCE', 'Newman')\n\n"
"('SOURCE', 'Bryson')\n\n"
"('SOURCE', 'Smith')\n\n"
"('SOURCE', 'Microsoft')\n\n"
"('SOURCE', 'John Havens')\n\n"
"('SOURCE', 'IPA')\n\n"
"('SOURCE', 'Amazon')\n\n"
"('SOURCE', 'Google')\n\n"
"('CLAIM_VERB', 'raised')\n\n"
"('SOURCE', 'IPA')\n\n"
"('CLAIM_VERB', 'showed')\n\n"
('(\'CLAIM_CONTENTS\', "that people\'s biggest privacy concern was their '
 'device being hacked (68.63%), followed by it collecting personal information '
 'on them (16%), listening to their conversations 24/7 (10%), recording '
 'private conversations (12%), not respecting their privacy (6%), storing '
 'their data (6%) and the \'creepy\' nature of the device (4%)")\n'
 '\n')
"('SOURCE', 'Manikonda')\n\n"
"('CLAIM_VERB', 'searched')\n\n"
"('SOURCE', 'Pasquale')\n\n"
"('SOURCE', 'Cadwalladr')\n\n"
"('SOURCE', 'Veale')\n\n"
"('SOURCE', 'EU')\n\n"
"('CLAIM_VERB', 'surrounds')\n\n"
"('SOURCE', 'Veale')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
("('CLAIM_CONTENTS', 'that extra protections should be given to people whose "
 'data have been used to train models, such as the right to access models; to '
 'know where they have originated from, and to whom they are being traded or '
 'transmitted; the right to erase themselves from a trained model; and the '
 "right to express a wish that the model not be used in the future.')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology 14')\n\n"
"('CLAIM_VERB', 'states')\n\n"
"('SOURCE', 'Wagner')\n\n"
"('SOURCE', 'Moon')\n\n"
"('SOURCE', 'Sauer')\n\n"
"('CLAIM_VERB', 'states')\n\n"
"('SOURCE', 'Bryson')\n\n"
"('SOURCE', 'India')\n\n"
"('SOURCE', 'Marda')\n\n"
"('CLAIM_VERB', 'profoundly')\n\n"
"('CLAIM_CONTENTS', 'affected by AI.')\n\n"
"('SOURCE', 'Li')\n\n"
"('SOURCE', 'Williams')\n\n"
"('SOURCE', 'India')\n\n"
"('SOURCE', 'Marda')\n\n"
"('SOURCE', 'The Indian Government')\n\n"
"('SOURCE', 'India')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('SOURCE', 'ProPublica')\n\n"
"('CLAIM_VERB', 'showed')\n\n"
("('CLAIM_CONTENTS', 'that COMPAS, a machine learning based software deployed "
 'in the US to assess the probability of a criminal defendant re-offending, '
 "was strongly biased against black Americans.')\n"
 '\n')
"('SOURCE', 'ProPublica')\n\n"
"('SOURCE', 'Amazon')\n\n"
"('SOURCE', 'Indian')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('CLAIM_VERB', 'shows')\n\n"
("('CLAIM_CONTENTS', 'users how a machine learning model is interpreting the "
 'data and how results can be quite disturbing.5 Implications As many '
 'machine-learning models are built from human-generated data, human biases '
 "can easily result in a skewed distribution in training data.')\n"
 '\n')
"('CLAIM_VERB', 'perpetuate')\n\n"
"('CLAIM_VERB', 'presidential')\n\n"
"('SOURCE', 'Brexit')\n\n"
"('SOURCE', 'Talavera')\n\n"
"('SOURCE', 'Trevor Paglen')\n\n"
"('SOURCE', 'Crawford')\n\n"
"('SOURCE', 'New York University')\n\n"
"('CLAIM_VERB', 'states')\n\n"
"('SOURCE', 'Bradshaw')\n\n"
"('SOURCE', 'Russia')\n\n"
"('SOURCE', 'Bradshaw')\n\n"
"('SOURCE', 'Howard')\n\n"
"('SOURCE', 'Azerbaijan')\n\n"
"('SOURCE', 'Iran')\n\n"
"('CLAIM_VERB', 'presidential')\n\n"
"('SOURCE', 'Cambridge Analytica')\n\n"
("('CLAIM_CONTENTS', 'published on online social platforms to be generally "
 "trustworthy (European Commission, 2017')\n"
 '\n')
"('SOURCE', 'Thurman')\n\n"
"('SOURCE', 'Gillespie')\n\n"
"('SOURCE', 'Harambam')\n\n"
"('SOURCE', 'Bartlett')\n\n"
"('CLAIM_VERB', 'promotes')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
"('SOURCE', 'Bartlett')\n\n"
"('SOURCE', 'Bartlett')\n\n"
"('CLAIM_VERB', 'perfectly')\n\n"
"('CLAIM_CONTENTS', 'happy with it')\n\n"
"('SOURCE', 'John Havens')\n\n"
"('CLAIM_VERB', 'robots')\n\n"
("('CLAIM_CONTENTS', 'that are loved and trusted could be misused to "
 "manipulate people (Scheutz 2012')\n"
 '\n')
"('CLAIM_VERB', 'ways')\n\n"
"('CLAIM_CONTENTS', 'that enhance their trustworthiness and appeal')\n\n"
"('SOURCE', 'Joseph Weizenbaum')\n\n"
"('CLAIM_VERB', 'showed')\n\n"
("('CLAIM_CONTENTS', 'that many early users were convinced of ELIZA’s "
 'intelligence and understanding, despite Weizenbaum’s insistence to the '
 "contrary')\n"
 '\n')
"('SOURCE', 'Borenstein')\n\n"
"('SOURCE', 'Arkin')\n\n"
("('CLAIM_CONTENTS', 'a duty that we have to ourselves to apprehend the world "
 "accurately.')\n"
 '\n')
"('SOURCE', 'Robots')\n\n"
"('CLAIM_CONTENTS', 'everyday relationships is also a possibility.')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
('(\'CLAIM_CONTENTS\', "that \'sexbots\' would distort people\'s perceptions '
 "about the value of a human being, increasing people's desire or willingness "
 'to harm others")\n'
 '\n')
"('CLAIM_VERB', 'punched')\n\n"
("('CLAIM_CONTENTS', 'a companion robot, would this be unethical (Lalji, "
 "2015')\n"
 '\n')
"('CLAIM_VERB', 'argue')\n\n"
("('CLAIM_CONTENTS', 'that robots could be an outlet for sexual desire, "
 "reducing the likelihood of violence, or to help recovery from assault')\n"
 '\n')
"('CLAIM_VERB', 'suite')\n\n"
"('SOURCE', 'Alexa')\n\n"
"('CLAIM_VERB', 'shows')\n\n"
("('CLAIM_CONTENTS', 'that robots have the capacity to change how cooperative "
 "we are.')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology 20')\n\n"
"('CLAIM_VERB', 'demonstrate')\n\n"
("('CLAIM_CONTENTS', 'that AI can improve the way humans relate to one "
 "another.')\n"
 '\n')
"('SOURCE', 'Christakis')\n\n"
("('CLAIM_CONTENTS', 'the legal status(es) of robots and AI systems over the "
 "past three decades')\n"
 '\n')
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'the European Commission')\n\n"
"('CLAIM_VERB', 'established')\n\n"
("('CLAIM_CONTENTS', 'as having the status of electronic persons responsible "
 'for making good any damage they may cause, and possibly applying electronic '
 'personality to cases where robots make autonomous decisions or otherwise '
 "interact with third parties independently')\n"
 '\n')
"('CLAIM_VERB', 'stated')\n\n"
('(\'CLAIM_CONTENTS\', "that \'the creation of a Legal Status of an '
 "'electronic person' for 'autonomous', 'unpredictable' and 'self-learning' "
 "robots' should be discarded from technical, legal and ethical "
 'perspectives.")\n'
 '\n')
"('SOURCE', 'Bryson')\n\n"
"('CLAIM_VERB', 'argues')\n\n"
('(\'CLAIM_CONTENTS\', "that giving robots moral agency could in itself be '
 "construed as an immoral action, as 'it would be unethical to put artefacts "
 'in a situation of competition with us, to make them suffer, or to make them '
 'unnecessarily mortal")\n'
 '\n')
"('SOURCE', 'Knight Capital Group')\n\n"
"('SOURCE', 'Knight Capital')\n\n"
("('CLAIM_CONTENTS', '460 million on the unintended trades, and the value of "
 "its own stock fell by almost 75%.')\n"
 '\n')
"('CLAIM_VERB', 'discuss')\n\n"
('(\'CLAIM_CONTENTS\', "several ways in which autonomous financial agents '
 'could commit financial crimes, including market manipulation, which is '
 "defined as 'actions and/or trades by market participants that attempt to "
 'influence market pricing artificially\' (Spatt, 2014")\n'
 '\n')
"('SOURCE', 'Lin')\n\n"
"('SOURCE', 'Lin')\n\n"
"('CLAIM_VERB', 'stocks')\n\n"
"('CLAIM_CONTENTS', '20 a share in a matter of few weeks (Ferrara 2015')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('CLAIM_VERB', 'maintain')\n\n"
"('CLAIM_VERB', 'anticipate')\n\n"
"('CLAIM_CONTENTS', 'by their programmers.')\n\n"
"('SOURCE', 'Wellman')\n\n"
"('SOURCE', 'Rajan')\n\n"
('(\'CLAIM_CONTENTS\', "the legal definition of market manipulation, which '
 'requires \'intent\'?")\n'
 '\n')
"('SOURCE', 'Rajan')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
("('CLAIM_CONTENTS', 'that trading agents will become increasingly capable of "
 'operating at wider levels without human oversight, and that regulation is '
 "now needed to prevent societal harm')\n"
 '\n')
("('CLAIM_CONTENTS', 'liable for tortious, criminal, and contractual "
 "misconduct involving AI and under what conditions')\n"
 '\n')
"('CLAIM_VERB', 'held')\n\n"
"('CLAIM_VERB', 'provides')\n\n"
("('CLAIM_CONTENTS', 'a great incentive for human agents to avoid finding out "
 'what precisely the machine learning system is doing, since the less the '
 'human agents know, the more they will be able to deny liability for both '
 "these reasons (Williams 2017')\n"
 '\n')
"('SOURCE', 'Williams')\n\n"
"('CLAIM_VERB', 'argues')\n\n"
("('CLAIM_CONTENTS', 'that mens rea with intent or knowledge is important, and "
 'we cannot simply abandon that key requirement of criminal liability in the '
 "face of difficulty in proving it')\n"
 '\n')
"('SOURCE', 'Kingston')\n\n"
"('CLAIM_VERB', 'references')\n\n"
"('CLAIM_CONTENTS', 'a definition provided by Hallevy (2010')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('CLAIM_VERB', 'relates')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('SOURCE', 'STOA')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 24')\n\n"
"('CLAIM_VERB', 'held')\n\n"
("('CLAIM_CONTENTS', 'liable as accomplices if they knew that a criminal "
 'offence was a natural or probable consequence of their program design or '
 "use')\n"
 '\n')
"('CLAIM_VERB', 'held')\n\n"
("('CLAIM_CONTENTS', 'liable under this scenario: the programmer, the vendor, "
 'the service provider, or the user (assuming that the system limitations and '
 'possible consequences of misuse are spelt out in the AI instructions – which '
 "is unlikely')\n"
 '\n')
"('CLAIM_VERB', 'attributes')\n\n"
"('CLAIM_CONTENTS', 'both actus and mens rea to an AI.')\n\n"
"('SOURCE', 'Kingston')\n\n"
"('CLAIM_VERB', 'vehicle')\n\n"
("('CLAIM_CONTENTS', 'that exceeds the speed limit could be held criminally "
 'liable for speeding – but for strict liability scenarios such as this, no '
 'criminal intent is required, and it is not necessary to prove that the car '
 "sped knowingly')\n"
 '\n')
"('SOURCE', 'Kingston')\n\n"
"('CLAIM_VERB', 'held')\n\n"
('(\'CLAIM_CONTENTS\', "liable for an AI\'s actions is important, but also '
 'potentially difficult")\n'
 '\n')
("('CLAIM_CONTENTS', 'that appointed an inadequate expert or programmer "
 "(Kingston, 2010')\n"
 '\n')
"('SOURCE', 'Weizenbaum')\n\n"
"('SOURCE', 'Europol')\n\n"
"('CLAIM_VERB', 'underwater')\n\n"
"('CLAIM_VERB', 'show')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('CLAIM_CONTENTS', 'liable.')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 26')\n\n"
"('SOURCE', 'the European Parliament Resolution')\n\n"
"('CLAIM_VERB', 'predicted')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('SOURCE', 'Atabekov')\n\n"
"('SOURCE', 'Yastrebov')\n\n"
"('SOURCE', 'European Parliament')\n\n"
"('SOURCE', 'Floridi')\n\n"
"('CLAIM_VERB', 'highlight')\n\n"
"('CLAIM_CONTENTS', 'the concept of ‘distributed agency’.')\n\n"
"('CLAIM_VERB', 'holds')\n\n"
"('SOURCE', 'Lokhorst')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'that the primary responsibility lies with a robot’s "
 'designer and deployer, but that a robot may be able to hold a certain level '
 "of responsibility for its actions.')\n"
 '\n')
"('SOURCE', 'Matthias')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('SOURCE', 'Matthias')\n\n"
"('CLAIM_VERB', 'proposes')\n\n"
('(\'CLAIM_CONTENTS\', "that the programmer of a neural network, for instance, '
 "increasingly becomes the 'creator of software organisms', with very little "
 'control past the point of coding")\n'
 '\n')
"('SOURCE', 'Matthias')\n\n"
"('SOURCE', 'Scherer')\n\n"
"('CLAIM_VERB', 'states')\n\n"
('(\'CLAIM_CONTENTS\', "that AI has so far been developed in \'a regulatory '
 "vacuum', with few laws or regulations designed to explicitly address the "
 'unique challenges of AI and responsibility.")\n'
 '\n')
"('CLAIM_VERB', 'bots')\n\n"
"('SOURCE', 'Bilge')\n\n"
"('SOURCE', 'Adobe')\n\n"
"('CLAIM_VERB', 'purposes')\n\n"
"('SOURCE', 'Lin')\n\n"
"('CLAIM_VERB', 'holds')\n\n"
("('CLAIM_CONTENTS', 'people liable for acting unreasonably under the "
 "circumstances (Anderson et al, 2009')\n"
 '\n')
"('CLAIM_VERB', 'show')\n\n"
('(\'CLAIM_CONTENTS\', "that: A duty of care is owed by the defendant to the '
 'plaintiff There has been a breach of that duty by the defendant There is a '
 "causal link between the defendant's breach of duty and the plaintiff's harm, "
 'and; That the plaintiff has suffered damages as a result")\n'
 '\n')
"('CLAIM_VERB', 'held')\n\n"
("('CLAIM_CONTENTS', 'responsible under the Product Liability doctrine, which "
 'holds manufacturers, distributors, suppliers, retailers, and others who make '
 'products available to the public responsible for the injuries those products '
 "cause.')\n"
 '\n')
"('SOURCE', 'Anderson')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 28')\n\n"
"('CLAIM_VERB', 'established')\n\n"
"('SOURCE', 'Khakurel')\n\n"
'(\'SOURCE\', "O\'Donoghue")\n\n'
"('CLAIM_VERB', 'exacerbate')\n\n"
"('SOURCE', 'Khakurel')\n\n"
("('CLAIM_CONTENTS', 'that in North America, over 100 million cell phones and "
 "300 million personal computers are discarded each year (')\n"
 '\n')
"('SOURCE', 'Guiltinana')\n\n"
"('SOURCE', 'McCallum')\n\n"
"('SOURCE', 'Iglinski')\n\n"
"('SOURCE', 'Norouzzadeh')\n\n"
"('CLAIM_VERB', 'ways')\n\n"
("('CLAIM_CONTENTS', 'that build trust and understanding, and respect human "
 "and civil rights (Dignum, 2018')\n"
 '\n')
"('CLAIM_VERB', 'maintain')\n\n"
"('CLAIM_CONTENTS', 'a human-in the loop, or give systems more autonomy.')\n\n"
"('SOURCE', 'European Commission')\n\n"
"('SOURCE', 'EU')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'that there is some way to go before people are "
 'comfortable with the widespread use of robots and advanced technology in '
 "society')\n"
 '\n')
"('CLAIM_VERB', 'areas')\n\n"
("('CLAIM_CONTENTS', 'that pose risk or difficulty to humans — space "
 'exploration, manufacturing, military, security, and search and rescue, for '
 'instance — they were very uncomfortable with areas involving vulnerable or '
 "dependent areas of society')\n"
 '\n')
"('SOURCE', 'Taddeo')\n\n"
"('SOURCE', 'Taddeo')\n\n"
"('SOURCE', 'Taddeo')\n\n"
("('CLAIM_CONTENTS', 'that a complete lack of supervision may lead to serious "
 'risks for our safety and security, as well for the rights and values '
 "underpinning our societies')\n"
 '\n')
"('SOURCE', 'Floridi')\n\n"
"('SOURCE', 'Taddeo')\n\n"
"('SOURCE', 'Taddeo')\n\n"
"('CLAIM_VERB', 'suggests')\n\n"
("('CLAIM_CONTENTS', 'that in the short term design could play a crucial role "
 "in addressing this problem')\n"
 '\n')
"('CLAIM_VERB', 'results')\n\n"
"('CLAIM_VERB', 'assessed')\n\n"
("('CLAIM_CONTENTS', 'how likely someone was to commit a violent crime was "
 "found to strongly discriminate against black people')\n"
 '\n')
"('SOURCE', 'Lapuschkin')\n\n"
"('CLAIM_CONTENTS', 'a copyright tag for the horse pictures')\n\n"
"('SOURCE', 'Corbett-Davies')\n\n"
"('CLAIM_VERB', 'describe')\n\n"
"('SOURCE', 'America')\n\n"
"('CLAIM_VERB', 'assessed')\n\n"
('(\'CLAIM_CONTENTS\', "the performance of teachers in Houston by comparing '
 'their students\' test scores against state averages (Sample, 2017")\n'
 '\n')
"('CLAIM_VERB', 'felt')\n\n"
"('CLAIM_CONTENTS', 'their civil rights.')\n\n"
"('CLAIM_VERB', 'highlights')\n\n"
("('CLAIM_CONTENTS', 'the importance of transparency for building trust in AI "
 '- it should always be possible to find out why an autonomous system made a '
 "particular decision, especially if that decision caused harm')\n"
 '\n')
"('SOURCE', 'STOA')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'ANN')\n\n"
"('SOURCE', 'ANN')\n\n"
"('SOURCE', 'ANN')\n\n"
"('SOURCE', 'The AI Now Institute')\n\n"
"('CLAIM_VERB', 'released')\n\n"
("('CLAIM_CONTENTS', 'a report which urged public agencies responsible for "
 'criminal justice, healthcare, welfare and education to ban black box AIs '
 "because their decisions cannot be explained')\n"
 '\n')
"('CLAIM_VERB', 'recommended')\n\n"
('(\'CLAIM_CONTENTS\', "that AIs should pass pre-release trials and be '
 "monitored 'in the wild' so that biases and other faults are swiftly "
 'corrected (AI Now Report, 2018")\n'
 '\n')
("('CLAIM_CONTENTS', '30,000, but would have been approved if it was "
 "£45,000.')\n"
 '\n')
"('SOURCE', 'Kroll')\n\n"
"('CLAIM_VERB', 'argues')\n\n"
("('CLAIM_CONTENTS', 'that, contrary to the criticism that black-box software "
 'systems are inscrutable, algorithms are fundamentally understandable pieces '
 "of technology')\n"
 '\n')
"('SOURCE', 'Kroll')\n\n"
"('CLAIM_VERB', 'argues')\n\n"
("('CLAIM_CONTENTS', 'that it is possible to place too much focus on "
 'understanding the mechanics of a tool, when the real focus should be on how '
 "that tool is put to use and in what context')\n"
 '\n')
"('SOURCE', 'Selbst')\n\n"
"('CLAIM_CONTENTS', 'how the tool is operated.')\n\n"
('(\'CLAIM_CONTENTS\', "the behaviour of humans — not by looking into their '
 "brain's neural circuitry, but by observing their behaviour and judging it "
 'against certain standards of conduct.")\n'
 '\n')
"('CLAIM_VERB', 'explanations')\n\n"
"('CLAIM_VERB', 'answers')\n\n"
"('CLAIM_CONTENTS', 'that originate from a machine (Cummings, 2004')\n\n"
"('SOURCE', 'Kroll')\n\n"
('(\'CLAIM_CONTENTS\', "that a borrower\'s quality of clothing correlates with '
 'their income and hence their creditworthiness")\n'
 '\n')
"('SOURCE', 'Larsson')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'a role for professional algorithm auditors, whose job "
 'would be to interrogate algorithms in order to ensure they comply with '
 "pre-set standards')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology 34')\n\n"
"('CLAIM_VERB', 'proposed')\n\n"
('(\'CLAIM_CONTENTS\', "a new class of algorithms, called oversight programs, '
 "whose function is to 'monitor, audit, and hold operational AI programs "
 'accountable\' (Etzioni and Etzioni 2016")\n'
 '\n')
"('CLAIM_VERB', 'caused')\n\n"
"('SOURCE', 'Jack Stilgoe')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('SOURCE', 'Caplan')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('SOURCE', 'Arizona')\n\n"
"('SOURCE', 'Jirotka')\n\n"
"('CLAIM_VERB', 'point')\n\n"
"('CLAIM_VERB', 'argues')\n\n"
("('CLAIM_CONTENTS', 'that one key element in building trust in AI is ethical "
 'governance – a set of processes, procedures, cultures and values designed to '
 "ensure the highest standards of behaviour.')\n"
 '\n')
"('CLAIM_VERB', 'adopted')\n\n"
"('SOURCE', 'Jirotka')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'that some robot types, driverless cars for instance, "
 'should be regulated through a body similar to the Civil Aviation Authority '
 '(CAA), with a driverless car equivalent of the Air Accident Investigation '
 "Branch')\n"
 '\n')
"('SOURCE', 'European Commission')\n\n"
"('CLAIM_VERB', 'showed')\n\n"
("('CLAIM_CONTENTS', 'that there was a generally positive view of robots and "
 "digitisation as long as this is implemented and managed carefully')\n"
 '\n')
"('SOURCE', 'EU')\n\n"
("('CLAIM_CONTENTS', 'that it surpasses human abilities, it may come to take "
 'control over our resources and outcompete our species, leading to human '
 "extinction')\n"
 '\n')
"('SOURCE', 'Bryson')\n\n"
("('CLAIM_CONTENTS', 'this threat is unlikely to occur, to maintain trust in "
 'AI, it is important that humans have ultimate oversight over this '
 "technology.')\n"
 '\n')
"('CLAIM_VERB', 'suggested')\n\n"
("('CLAIM_CONTENTS', 'by researchers is that of always keeping a "
 "human-in-the-loop (HITL)')\n"
 '\n')
"('SOURCE', 'HITL')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
('(\'CLAIM_CONTENTS\', "that human operators should be able to monitor the '
 "behaviour of LAWS, or 'killer robots,' or credit scoring algorithms (Citron "
 'and Pasquale 2014")\n'
 '\n')
"('SOURCE', 'Rahwan')\n\n"
"('SOURCE', 'Rahwan')\n\n"
"('SOURCE', 'HITL')\n\n"
"('SOURCE', 'Rahwan')\n\n"
"('CLAIM_VERB', 'proposed')\n\n"
("('CLAIM_CONTENTS', 'ways to stop an AI system before it has a chance to "
 "escape outside control and cause harm')\n"
 '\n')
"('SOURCE', 'STOA')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('CLAIM_VERB', 'anticipate')\n\n"
('(\'CLAIM_CONTENTS\', "this move and defend itself by learning to disable its '
 'own \'kill switch")\n'
 '\n')
"('SOURCE', 'Orseau')\n\n"
"('SOURCE', 'Armstrong')\n\n"
"('CLAIM_VERB', 'recently')\n\n"
("('CLAIM_CONTENTS', 'published a paper about how to prevent AI programmed "
 'through reinforcement learning (RL) from seeing interruptions as a '
 "threat.')\n"
 '\n')
"('CLAIM_VERB', 'propose')\n\n"
"('CLAIM_CONTENTS', 'that is also interruptible')\n\n"
"('SOURCE', 'Harrison')\n\n"
"('CLAIM_VERB', 'suggests')\n\n"
('(\'CLAIM_CONTENTS\', "making a \'big red button\' that, once pressed, '
 'diverted the AI into a simulated world where it could pursue its reward '
 'functions without causing any harm")\n'
 '\n')
"('CLAIM_VERB', 'maintain')\n\n"
"('SOURCE', 'Hadfield-Menell')\n\n"
"('SOURCE', 'Arnold')\n\n"
"('SOURCE', 'Schultz')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
('(\'CLAIM_CONTENTS\', "that the \'red button\' approach comes at the point '
 "when a system has already 'gone rogue' and seeks to obstruct interference, "
 "and that 'big red button' approaches focus on long-term threats, imagining "
 'systems considerably more advanced than exist today and neglecting the '
 'present day problems with keeping automated systems accountable")\n'
 '\n')
"('SOURCE', 'Arnold')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
('(\'CLAIM_CONTENTS\', "that to achieve this AIs should contain an ethical '
 'core (EC) consisting of a scenario-generation mechanism and a simulation '
 "environment used to test a system's decisions in simulated worlds, rather "
 'than the real world")\n'
 '\n')
"('SOURCE', 'EC')\n\n"
"('SOURCE', 'EC')\n\n"
"('SOURCE', 'ICT')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 38')\n\n"
"('SOURCE', 'The Institute for Ethics in Artificial Intelligence Germany')\n\n"
"('CLAIM_CONTENTS', '7.5 million over five years')\n\n"
"('SOURCE', 'The Institute for Ethical AI & Machine Learning')\n\n"
("('CLAIM_CONTENTS', 'eight principles for responsible machine learning: these "
 'concern the maintenance of human control, appropriate redress for AI impact, '
 'evaluation of bias, explicability, transparency, reproducibility, mitigation '
 'of the effect of AI automation on workers, accuracy, cost, privacy, trust, '
 "and security')\n"
 '\n')
"('SOURCE', 'The Institute for Ethical Artificial Intelligence')\n\n"
"('SOURCE', 'The Future of Life Institute')\n\n"
"('SOURCE', 'Elon Musk')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Jaan Tallinn')\n\n"
"('SOURCE', 'Matt Wage')\n\n"
"('SOURCE', 'Nisan Stiennon')\n\n"
"('SOURCE', 'Sam Harris')\n\n"
"('SOURCE', 'George Godula')\n\n"
"('SOURCE', 'Jacob Trefethen')\n\n"
"('SOURCE', 'The Association for Computing Machinery')\n\n"
"('CLAIM_VERB', 'States')\n\n"
"('SOURCE', 'The Japanese Society for Artificial Intelligence')\n\n"
"('SOURCE', 'Google The Future Society')\n\n"
"('CLAIM_VERB', 'States')\n\n"
("('CLAIM_CONTENTS', 'The impact and governance of artificial intelligence to "
 'broadly benefit society, spanning policy research, advisory and collective '
 "intelligence, coordination of governance, law, and education')\n"
 '\n')
"('SOURCE', 'The AI')\n\n"
"('CLAIM_VERB', 'States')\n\n"
"('SOURCE', 'the MacArthur Foundation')\n\n"
"('SOURCE', 'Microsoft Research')\n\n"
"('SOURCE', 'Google')\n\n"
"('SOURCE', 'the Ford Foundation')\n\n"
"('SOURCE', 'The Institute of Electrical and Electronics Engineers')\n\n"
"('SOURCE', 'The Partnership on AI United')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'IBM')\n\n"
"('SOURCE', 'Microsoft')\n\n"
"('SOURCE', 'The Foundation for Responsible Robotics')\n\n"
"('SOURCE', 'The Miami Foundation')\n\n"
"('SOURCE', 'Knight Foundation')\n\n"
"('SOURCE', 'Flora Hewlett Foundation')\n\n"
"('SOURCE', 'Saidot')\n\n"
"('SOURCE', 'The Association for Computing Machinery')\n\n"
"('SOURCE', 'Université de Montréal')\n\n"
"('SOURCE', 'The UNI Global Union Switzerland Worker')\n\n"
"('SOURCE', 'The European Robotics Research Network')\n\n"
"('SOURCE', 'Sweden')\n\n"
"('SOURCE', 'The European Robotics Platform')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('CLAIM_VERB', 'researched')\n\n"
"('CLAIM_VERB', 'proposed')\n\n"
"('CLAIM_CONTENTS', 'approaches and solutions to protect from harms')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('CLAIM_VERB', 'ways')\n\n"
("('CLAIM_CONTENTS', 'that threaten the safety ofeither itself or "
 'others?6.Social harm and social justice How do we ensure that AI is '
 'inclusive, free of bias and discrimination, and aligned with publicmorals '
 'and ethics?7.Financial harmHow will we control for AI that negatively '
 'affects economic opportunity and employment, and either takes jobs from '
 'human workers or decreases the opportunity and quality of these '
 'jobs?8.Lawfulness and justice How do we go about ensuring that AI - and the '
 'data it collects - is used, processed, andmanaged in a way that is just, '
 'equitable, and lawful, and subject to appropriate governanceand '
 "regulation?')\n"
 '\n')
"('CLAIM_VERB', 'associated')\n\n"
"('CLAIM_VERB', 'establish')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'proposed')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 44')\n\n"
"('SOURCE', 'the Ethically Aligned Design')\n\n"
"('SOURCE', 'European Parliament')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'recommends')\n\n"
("('CLAIM_CONTENTS', 'new governance frameworks, standards, and regulatory "
 'bodies which oversee the use of AI; translating existing legal obligations '
 'into informed policy, allowing for cultural norms and legal frameworks; and '
 'always maintaining complete human control over AI, without granting them '
 "rights or privileges equal to those of humans (IEEE, 2019')\n"
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'prioritising human well-being throughout the design "
 'phase, and using the best and most widely-accepted available metrics to '
 "clearly measure the societal success of an AI.')\n"
 '\n')
("('CLAIM_CONTENTS', 'ways to identify and trace the impingement of rights, "
 "and to offer appropriate redress and reform.')\n"
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'the Foundation for Responsible Robotics')\n\n"
"('SOURCE', 'The Future of Life Institute')\n\n"
"('SOURCE', 'the Japanese Society for AI Ethical Guidelines')\n\n"
"('SOURCE', 'The Future Society')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'Montréal')\n\n"
"('CLAIM_VERB', 'endowed')\n\n"
"('SOURCE', 'the UNI Global Union')\n\n"
"('SOURCE', 'Union')\n\n"
"('CLAIM_VERB', 'states')\n\n"
("('CLAIM_CONTENTS', 'that we must ensure that AI serves people and the "
 'planet, and both protects and increases fundamental human rights, human '
 'dignity, integrity, freedom, privacy, and cultural and gender '
 "diversity10.')\n"
 '\n')
"('CLAIM_VERB', 'ways')\n\n"
('(\'CLAIM_CONTENTS\', "that have not yet been qualified; humans are '
 'susceptible to emotional influence both positively and negatively, and '
 "'affect' – how emotion and desire influence behaviour – is a core part of "
 'intelligence.")\n'
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'recommend')\n\n"
("('CLAIM_CONTENTS', 'various ways to mitigate this risk, including the "
 'ability to adapt and update AI norms and values according to who they are '
 'engaging with, and the sensitivities of the culture in which they are '
 "operating.')\n"
 '\n')
"('SOURCE', 'the AI Now institute')\n\n"
"('SOURCE', 'the European Robotics Research Network')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'subtly')\n\n"
"('CLAIM_VERB', 'behaviours')\n\n"
"('CLAIM_CONTENTS', 'that worsen human health')\n\n"
"('CLAIM_VERB', 'analyses')\n\n"
"('CLAIM_VERB', 'raised')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'IEEE')\n\n"
('(\'CLAIM_CONTENTS\', "that AI must be auditable, in order to assure that the '
 'designers, manufacturers, owners, and operators of AI are held accountable '
 "for the technology or system's actions, and are thus considered responsible "
 'for any potential harm it might cause")\n'
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'The Future of Life Institute')\n\n"
"('SOURCE', 'The Partnership on AI')\n\n"
"('SOURCE', 'the Foundation for Responsible Robotics')\n\n"
"('CLAIM_VERB', 'published')\n\n"
("('CLAIM_CONTENTS', 'a report on ‘Our Sexual Future with Robots’ (Foundation "
 "for Responsible Robotics, 2019')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology 48 Access')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'propose')\n\n"
("('CLAIM_CONTENTS', 'developing new standards that detail measurable and "
 'testable levels of transparency, so systems can be objectively assessed for '
 "their compliance')\n"
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'PII')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'PII')\n\n"
"('CLAIM_VERB', 'established')\n\n"
("('CLAIM_CONTENTS', 'as the asset of the individual (by Regulation (EU) "
 '2016/679 in Europe, for example), and systems must ask for explicit consent '
 'at the time data are collected and used, in order to protect individual '
 "autonomy, dignity and right to consent')\n"
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'The Future of Life Institute')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'blur')\n\n"
('(\'CLAIM_CONTENTS\', "the distinction between agents and patients and may '
 "encourage anthropomorphic expectations of machines', writes the IEEE — "
 'especially as embodied AI begins to look increasingly similar to humans.")\n'
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'propose')\n\n"
('(\'CLAIM_CONTENTS\', "cultivating a \'safety mindset\' among researchers, to '
 "'identify and pre-empt unintended and unanticipated behaviors in their "
 "systems' and to develop systems which are 'safe by design'; setting up "
 'review boards at institutions as a resource and means of evaluating projects '
 'and their progress; encouraging a community of sharing, to spread the word '
 'on safety-related developments, research, and tools")\n'
 '\n')
"('SOURCE', 'The Future of Life Institute')\n\n"
"('CLAIM_VERB', 'indicate')\n\n"
('(\'CLAIM_CONTENTS\', "that all involved in developing and deploying AI '
 "should be mission-led, adopting the norm that AI 'should only be developed "
 'in the service of widely shared ethical ideals, and for the benefit of all '
 "humanity rather than one state or organisation' (Future of Life Institute, "
 '2017")\n'
 '\n')
"('SOURCE', 'The Japanese Society for AI')\n\n"
"('CLAIM_VERB', 'proposes')\n\n"
("('CLAIM_CONTENTS', 'that AI should act with integrity at all times, and that "
 'AI and society should earnestly seek to learn from and communicate with one '
 "another')\n"
 '\n')
"('SOURCE', 'The Partnership on AI')\n\n"
"('SOURCE', 'The Institute for Ethical AI & Machine Learning')\n\n"
"('CLAIM_VERB', 'mandating')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
("('CLAIM_CONTENTS', 'that all should have access to the benefits of AI, and "
 "it should work for the common good.')\n"
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
('(\'CLAIM_CONTENTS\', "first identifying social and moral norms of the '
 'specific community in which an AI will be deployed, and those around the '
 "specific task or service it will offer; designing AI with the idea of 'norm "
 "updating' in mind, given that norms are not static and AI must change "
 'dynamically and transparently alongside culture; and identifying the ways in '
 'which people resolve norm conflicts, and equipping AI with a system in which '
 'to do so in a similar and transparent way")\n'
 '\n')
"('CLAIM_VERB', 'biases')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'AI4All')\n\n"
"('SOURCE', 'the AI Now Institute')\n\n"
"('CLAIM_STRENGTH', 'explicitly')\n\n"
"('CLAIM_VERB', 'advocate')\n\n"
("('CLAIM_CONTENTS', 'for fair, diverse, equitable, and non-discriminatory "
 'inclusion in AI at all stages, with a focus on support for under-represented '
 "groups')\n"
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'ethicists')\n\n"
"('CLAIM_CONTENTS', 'that can steer and support value-based innovation.')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'suggests')\n\n"
("('CLAIM_CONTENTS', 'taking action and investing to mitigate the inequality "
 'gap; integrating corporate social responsibility (CSR) into development and '
 'marketing; developing transparent power structures; facilitating and sharing '
 'robotics and AI knowledge and research; and generally keeping AI in line '
 "with the US Sustainable Development Goals11')\n"
 '\n')
"('CLAIM_VERB', 'held')\n\n"
"('SOURCE', 'the Japanese Society for AI')\n\n"
"('SOURCE', 'The Foundation for Responsible Robotics')\n\n"
"('SOURCE', 'Saidot')\n\n"
"('SOURCE', 'Saidot')\n\n"
"('SOURCE', 'the Future of Life Institute')\n\n"
('(\'CLAIM_CONTENTS\', "a need for AI imbued with human values of cultural '
 'diversity and human rights; and the Institute for Ethical AI & Machine '
 "Learning includes 'bias evaluation' for monitoring bias in AI development "
 'and production.")\n'
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'The UNI Global Union')\n\n"
"('SOURCE', 'The AI Now Institute')\n\n"
"('SOURCE', 'The Future Society')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'RRI')\n\n"
"('SOURCE', 'Von Schomberg')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'conclude')\n\n"
('(\'CLAIM_CONTENTS\', "that AI should not be granted any level of '
 "'personhood', and that, while development, design and distribution of AI "
 'should fully comply with all applicable international and domestic law, '
 'there is much work to be done in defining and implementing the relevant '
 'legislation.")\n'
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'that AI should remain subject to the applicable regimes "
 'of property law; that stakeholders should identify the types of decisions '
 'that should never be delegated to AI, and ensure effective human control '
 'over those decisions via rules and standards; that existing laws should be '
 'scrutinised and reviewed for mechanisms that could practically give AI legal '
 'autonomy; and that manufacturers and operators should be required to comply '
 'with the applicable laws of all jurisdictions in which an AI could '
 "operate')\n"
 '\n')
"('CLAIM_VERB', 'recommend')\n\n"
("('CLAIM_CONTENTS', 'that governments reassess the legal status for AI as "
 'they become more sophisticated, and work closely with regulators, societal '
 'and industry actors and other stakeholders to ensure that the interests of '
 'humanity – and not the development of systems themselves – remain the '
 "guiding principle.')\n"
 '\n')
"('SOURCE', 'RRI')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'RRI')\n\n"
("('CLAIM_CONTENTS', 'the chances of design being both relevant and strong in "
 "terms of ethical alignment')\n"
 '\n')
"('SOURCE', 'RRI')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 52')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'suggests')\n\n"
('(\'CLAIM_CONTENTS\', "new ways of educating the public on ethics and '
 "security issues, for example a 'data privacy' warning on smart devices that "
 'collect personal data; delivering this education in scalable, effective '
 'ways; and educating government, lawmakers, and enforcement agencies '
 'surrounding these issues, so they can work collaboratively with citizens – '
 'in a similar way to police officers providing safety lectures in schools – '
 'and avoid fear and confusion (IEEE, 2019")\n'
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'EAD')\n\n"
"('CLAIM_VERB', 'state')\n\n"
('(\'CLAIM_CONTENTS\', "that AI must do no harm to Earth\'s natural systems or '
 'exacerbate their degradation, and contribute to realising sustainable '
 "stewardship, preservation, and/or the restoration of Earth's natural "
 'systems")\n'
 '\n')
"('SOURCE', 'The UNI Global Union')\n\n"
"('CLAIM_VERB', 'state')\n\n"
('(\'CLAIM_CONTENTS\', "that AI must put people and the planet first, striving '
 "to protect and even enhance our planet's biodiversity and ecosystems (UNI "
 'Global Union, n.d")\n'
 '\n')
"('SOURCE', 'The Foundation for Responsible Robotics')\n\n"
"('SOURCE', 'IEEE')\n\n"
('(\'CLAIM_CONTENTS\', "the \'Internet of Other People\'s Things\' (IEEE, '
 '2019")\n'
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'employee data impact assessments to deal with these "
 'corporate nuances and ensure that no data is collected without employee '
 "consent.')\n"
 '\n')
"('CLAIM_VERB', 'stated')\n\n"
("('CLAIM_CONTENTS', 'purposes, kept up-to-date, lawfully processed, and not "
 "kept for a longer period than necessary.')\n"
 '\n')
"('CLAIM_VERB', 'noting')\n\n"
"('CLAIM_VERB', 'shield')\n\n"
("('CLAIM_CONTENTS', 'the natural persons behind them from the implications of "
 "the law.')\n"
 '\n')
"('SOURCE', 'The UNI Global Union')\n\n"
"('CLAIM_VERB', 'asserts')\n\n"
("('CLAIM_CONTENTS', 'that legal responsibility lies with the creator, not the "
 "robot itself, and calls for a ban on attributing responsibility to robots')\n"
 '\n')
"('SOURCE', 'Lower Middle Income Countries')\n\n"
"('CLAIM_VERB', 'maintain')\n\n"
("('CLAIM_CONTENTS', 'that clear, open and transparent dialogue between AI and "
 "society is key to the creation of understanding, acceptance, and trust.')\n"
 '\n')
"('SOURCE', 'the Future of Life Institute')\n\n"
"('CLAIM_CONTENTS', 'that are at odds with those of humans')\n\n"
"('SOURCE', 'The Future of Life Institute')\n\n"
"('CLAIM_VERB', 'poses')\n\n"
("('CLAIM_CONTENTS', 'a threat in the form of autonomous weapons systems "
 "(AWS).')\n"
 '\n')
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'AWS')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'audit trails to guarantee accountability and control; "
 'adaptive learning systems that can explain their reasoning in a transparent, '
 'understandable way; that human operators of autonomous systems are '
 'identifiable, held responsible, and aware of the implications of their work; '
 'that autonomous behaviour is predictable; and that professional codes of '
 'ethics are developed to address the development of autonomous systems – '
 "especially those intended to cause harm')\n"
 '\n')
"('SOURCE', 'AWS')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('CLAIM_VERB', 'recommend')\n\n"
("('CLAIM_CONTENTS', 'that systems designed to act outside the boundaries of "
 'human control or judgement are unethical and violate fundamental human '
 "rights and legal accountability for weapons use.')\n"
 '\n')
"('SOURCE', 'the Foundation for Responsible Robotics')\n\n"
"('SOURCE', 'the UNI Global Union')\n\n"
"('SOURCE', 'FLI')\n\n"
"('SOURCE', 'STOA')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'Philadelphia')\n\n"
"('SOURCE', 'Volkswagen')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Lin')\n\n"
"('CLAIM_VERB', 'poses')\n\n"
"('CLAIM_VERB', 'establish')\n\n"
"('SOURCE', 'The Washington Post')\n\n"
"('CLAIM_VERB', 'strengths')\n\n"
"('CLAIM_VERB', 'reached')\n\n"
("('CLAIM_CONTENTS', 'this conclusion because asthmatic pneumonia patients "
 'were taken directly to intensive care, and this higher-level care '
 "circumvented complications')\n"
 '\n')
"('SOURCE', 'Schönberger')\n\n"
"('CLAIM_VERB', 'establish')\n\n"
"('CLAIM_VERB', 'established')\n\n"
"('CLAIM_VERB', 'establish')\n\n"
("('CLAIM_CONTENTS', 'what went wrong during a procedure and whether anyone, "
 "medical personnel or machine, is to blame')\n"
 '\n')
"('CLAIM_VERB', 'establish')\n\n"
"('CLAIM_CONTENTS', 'the liable party in most cases')\n\n"
"('SOURCE', 'Guardian')\n\n"
"('SOURCE', 'EU')\n\n"
"('CLAIM_VERB', 'accurate')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 56')\n\n"
"('SOURCE', 'Google')\n\n"
"('SOURCE', 'IBM')\n\n"
"('SOURCE', 'Microsoft')\n\n"
"('SOURCE', 'Guardian')\n\n"
"('CLAIM_VERB', 'hope')\n\n"
"('SOURCE', 'Guardian')\n\n"
"('CLAIM_VERB', 'suggests')\n\n"
("('CLAIM_CONTENTS', 'that an extensive social network offers protection "
 "against dementia')\n"
 '\n')
"('SOURCE', 'Californian')\n\n"
"('CLAIM_VERB', 'argued')\n\n"
"('SOURCE', 'Guardian')\n\n"
"('SOURCE', 'Press Association')\n\n"
"('SOURCE', 'KALW')\n\n"
"('SOURCE', 'Turkle')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
('(\'CLAIM_CONTENTS\', "that \'the fact that our parents, grandparents and '
 "children might say 'I love you' to a robot who will say 'I love you' in "
 'return, does not feel completely comfortable")\n'
 '\n')
"('SOURCE', 'Allen')\n\n"
"('CLAIM_VERB', 'agree')\n\n"
("('CLAIM_CONTENTS', 'that robots designed to detect human social gestures and "
 "respond in kind all use techniques that are arguably forms of deception.')\n"
 '\n')
"('CLAIM_VERB', 'state')\n\n"
('(\'CLAIM_CONTENTS\', "deteriorates and they become confused — someone with '
 "Alzheimer's could forget that a robot was monitoring them, and could perform "
 'acts or say things thinking that they are in the privacy of their own '
 'home")\n'
 '\n')
"('SOURCE', 'John Havens')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 58')\n\n"
('(\'CLAIM_CONTENTS\', "film \'I, Robot\', where Will Smith\'s character '
 'disagreed with how the robots of the fictional time used cold logic to save '
 'his life over that of a child\'s")\n'
 '\n')
"('SOURCE', 'Goldhill')\n\n"
"('CLAIM_VERB', 'write')\n\n"
("('CLAIM_CONTENTS', 'that AI may affect human-human interactions and "
 'relationships within the healthcare domain, particularly that between '
 'patient and doctor, and potentially disrupt the trust we place in our '
 "doctor')\n"
 '\n')
"('CLAIM_VERB', 'shows')\n\n"
"('SOURCE', 'Guardian')\n\n"
('(\'CLAIM_CONTENTS\', "that they have specific skills, knowledge, and values '
 'such as \'do no harm")\n'
 '\n')
"('CLAIM_VERB', 'licensed')\n\n"
"('SOURCE', 'Guardian')\n\n"
"('SOURCE', 'Guardian')\n\n"
"('CLAIM_VERB', 'available')\n\n"
('(\'CLAIM_CONTENTS\', "that can perform up to a third of nurses\' work (Tech '
 'Times, 2018")\n'
 '\n')
"('CLAIM_VERB', 'concluded')\n\n"
('(\'CLAIM_CONTENTS\', "that \'these technologies will not replace healthcare '
 "professionals but will enhance them ('augment them'), giving them more time "
 'to care for patients\'.")\n'
 '\n')
"('SOURCE', 'NHS')\n\n"
"('CLAIM_VERB', 'maintain')\n\n"
("('CLAIM_CONTENTS', 'a set speed (e.g. Cruise Control), engine and brake "
 'power to maintain and vary speed (e.g. Adaptive Cruise Control), or steering '
 "(e.g. Parking Assistance')\n"
 '\n')
"('SOURCE', 'AV')\n\n"
"('CLAIM_VERB', 'established')\n\n"
"('SOURCE', 'John Havens')\n\n"
'(\'CLAIM_CONTENTS\', "driving\' functions are legal in most countries")\n\n'
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'STOA')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('CLAIM_VERB', 'pose')\n\n"
"('SOURCE', 'the Ethics Commission')\n\n"
"('CLAIM_VERB', 'highlights')\n\n"
('(\'CLAIM_CONTENTS\', "that it is the public sector\'s responsibility to '
 'guarantee the safety of AV systems introduced and licensed on public roads, '
 'and recommends that all AV driving systems be subject to official licensing '
 'and monitoring (Ethics Commision, 2017")\n'
 '\n')
"('CLAIM_VERB', 'suggested')\n\n"
("('CLAIM_CONTENTS', 'that the AV industry is entering its most dangerous "
 'phase, with cars being not yet fully autonomous but human operators not '
 "being fully engaged (Solon, 2018')\n"
 '\n')
"('SOURCE', 'Arizona')\n\n"
"('SOURCE', 'Elaine Herzberg')\n\n"
"('SOURCE', 'Shepherdson')\n\n"
"('SOURCE', 'Somerville')\n\n"
"('SOURCE', 'NTSB')\n\n"
"('CLAIM_VERB', 'said')\n\n"
('(\'CLAIM_CONTENTS\', "that the driver is relied upon to intervene and take '
 'action in situations requiring emergency braking – leading some commentators '
 'to call out the misleading communication to consumers around the terms '
 '\'self-driving cars\' and \'autopilot\' (Leggett, 2018")\n'
 '\n')
"('SOURCE', 'Bradshaw')\n\n"
"('SOURCE', 'Toyota')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Volkswagen')\n\n"
"('CLAIM_VERB', 'show')\n\n"
"('SOURCE', 'Gao Yaning')\n\n"
"('SOURCE', 'Tesla Model S')\n\n"
"('CLAIM_VERB', 'crashed')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('CLAIM_VERB', 'state')\n\n"
("('CLAIM_CONTENTS', 'that the damage to the vehicle made it impossible to "
 'determinewhether Autopilot was engaged and, if so, whether it '
 "malfunctioned.')\n"
 '\n')
"('SOURCE', 'Joshua Brown')\n\n"
"('SOURCE', 'the National Highwaysand Transport Safety Agency')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Gibbs')\n\n"
"('SOURCE', 'the National Highway Traffic Safety Administration')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Wei Huang')\n\n"
"('CLAIM_VERB', 'crashed')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'The National Transportation Safety Board')\n\n"
"('CLAIM_VERB', 'published')\n\n"
("('CLAIM_CONTENTS', 'a reportattributing the crash to an Autopilot navigation "
 "mistake')\n"
 '\n')
"('SOURCE', 'Tesla')\n\n"
"('CLAIM_VERB', 'mean')\n\n"
("('CLAIM_CONTENTS', 'that accident investigators rely heavily on the "
 'cooperation of manufacturers to provide critical data on the events leading '
 "up to an accident (Stilgoe and Winfield, 2018')\n"
 '\n')
"('SOURCE', 'Californian')\n\n"
"('SOURCE', 'Lin')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Guardian')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'Thielman')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('CLAIM_VERB', 'proposed')\n\n"
("('CLAIM_CONTENTS', 'by the German Ethics Commission on Automated Driving, is "
 'to ensure that that all AV drivers be given full data sovereignty (Ethics '
 "Commission, 2017')\n"
 '\n')
"('SOURCE', 'Viscelli')\n\n"
"('SOURCE', 'Isaac')\n\n"
"('SOURCE', 'AV')\n\n"
"('SOURCE', 'Cannon')\n\n"
"('SOURCE', 'Edinburgh')\n\n"
"('SOURCE', 'BBC')\n\n"
"('CLAIM_VERB', 'shuttle')\n\n"
"('SOURCE', 'CNN')\n\n"
"('CLAIM_VERB', 'routes')\n\n"
"('CLAIM_CONTENTS', 'that travel along 100% dedicated bus lanes')\n\n"
"('SOURCE', 'the Transport Workers Union of America')\n\n"
"('SOURCE', 'BBC')\n\n"
("('CLAIM_CONTENTS', 'significantly — again, something with implications for "
 "urban planning (Khosravi, 2018')\n"
 '\n')
"('CLAIM_VERB', 'will')\n\n"
('(\'CLAIM_CONTENTS\', "need to make judgement calls in conditions of '
 'uncertainty, or \'no win\' situations")\n'
 '\n')
"('SOURCE', 'Lin')\n\n"
"('CLAIM_VERB', 'explain')\n\n"
"('SOURCE', 'Loh')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
("('CLAIM_CONTENTS', 'that responsibility should be shared among the "
 "engineers, the driver and the autonomous driving system itself')\n"
 '\n')
"('SOURCE', 'Millar')\n\n"
"('CLAIM_VERB', 'suggests')\n\n"
("('CLAIM_CONTENTS', 'that the user of the technology, in this case the "
 'passenger in the self-driving car, should be able to decide what ethical or '
 "behavioural principles the robot ought to follow')\n"
 '\n')
"('CLAIM_VERB', 'argues')\n\n"
("('CLAIM_CONTENTS', 'that there would be a moral outcry if engineers designed "
 'cars without either asking the driver directly for their input, or informing '
 'the user ahead of time how the car is programmed to behave in certain '
 "situations')\n"
 '\n')
"('CLAIM_CONTENTS', 'a turning point in the use of automation in warfare.')\n\n"
"('SOURCE', 'Allen')\n\n"
"('CLAIM_VERB', 'conducted')\n\n"
("('CLAIM_CONTENTS', 'a poll asking people what they thought an autonomous car "
 'in which they were a passenger should do if a child stepped out in front of '
 "the vehicle in a tunnel')\n"
 '\n')
"('CLAIM_VERB', 'said')\n\n"
"('CLAIM_CONTENTS', 'that lawmakers should choose')\n\n"
"('CLAIM_VERB', 'said')\n\n"
("('CLAIM_CONTENTS', 'that the car’s manufacturers should make the "
 "decision.')\n"
 '\n')
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'that people do not like the idea of engineers making "
 "moral decisions on their behalf.')\n"
 '\n')
"('SOURCE', 'Millar')\n\n"
"('CLAIM_VERB', 'suggests')\n\n"
("('CLAIM_CONTENTS', 'a ‘setup’ procedure where people could choose their "
 "ethics settings after purchasing a new car.')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology 64')\n\n"
"('SOURCE', 'The Russian Military Industrial Committee')\n\n"
"('SOURCE', 'Russian')\n\n"
"('SOURCE', 'the United States Department of Defense')\n\n"
("('CLAIM_CONTENTS', '1,000, meaning that for the price of a single high-end "
 "aircraft, a military could acquire one million drones')\n"
 '\n')
"('SOURCE', 'Improvised Explosive Devices')\n\n"
"('CLAIM_VERB', 'within')\n\n"
("('CLAIM_CONTENTS', 'a fluid battlefield environment that automatically "
 'scanned satellite imagery to detect specific vehicle types, helping to '
 "identify threats in advance.')\n"
 '\n')
"('CLAIM_VERB', 'stipulates')\n\n"
("('CLAIM_CONTENTS', 'that any attack needs to distinguish between combatants "
 'and non-combatants, be proportional and must not target civilians or '
 "civilian objects')\n"
 '\n')
"('SOURCE', 'Tamburrini')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
('(\'CLAIM_CONTENTS\', "that: \'[LAWS must be] capable of respecting the '
 'principles of distinction and proportionality at least as well as a '
 'competent and conscientious human soldier")\n'
 '\n')
"('SOURCE', 'Lim')\n\n"
"('SOURCE', 'Asaro')\n\n"
"('CLAIM_VERB', 'argues')\n\n"
'(\'CLAIM_CONTENTS\', "that it doesn\'t matter how good LAWS get")\n\n'
"('CLAIM_VERB', 'argue')\n\n"
('(\'CLAIM_CONTENTS\', "that delegating the decision to kill a human to a '
 "machine is an infringement of basic human dignity, as robots don't feel "
 'emotion, and can have no notion of sacrifice and what it means to take a '
 'life")\n'
 '\n')
"('SOURCE', 'Lim')\n\n"
"('CLAIM_VERB', 'explain')\n\n"
'(\'CLAIM_CONTENTS\', "the \'wrong\' person")\n\n'
"('SOURCE', 'Johnson')\n\n"
"('CLAIM_VERB', 'argue')\n\n"
("('CLAIM_CONTENTS', 'that there is no particular reason why being killed by a "
 'machine would be a subjectively worse, or less dignified, experience than '
 "being killed by a cruise missile strike')\n"
 '\n')
"('SOURCE', 'Lim')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('SOURCE', 'Schmit')\n\n"
"('CLAIM_VERB', 'argues')\n\n"
("('CLAIM_CONTENTS', 'that the responsibility for committing war crimes should "
 'fall on both the individual who programmed the AI, and the commander or '
 'supervisor (assuming that they knew, or should have known, the autonomous '
 'weapon system had been programmed and employed in a war crime, and that they '
 "did nothing to stop it from happening')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
("('CLAIM_CONTENTS', 'new generation of ethical standards are emerging as the "
 'ethical, legal and societal impacts of artificial intelligence and robotics '
 "are further understood')\n"
 '\n')
"('CLAIM_VERB', 'articulates')\n\n"
("('CLAIM_CONTENTS', 'explicit or implicit ethical concerns, all standards "
 "embody some kind of ethical principle (Winfield, 2019a')\n"
 '\n')
"('SOURCE', 'British Standard BS')\n\n"
("('CLAIM_CONTENTS', 'that can learn and the implications of robot enhancement "
 'that arise, and the standard argues that the ethical risk associated with '
 'the use of a robot should not exceed the risk of the same activity when '
 "conducted by a human')\n"
 '\n')
"('SOURCE', 'British Standard BS')\n\n"
"('CLAIM_VERB', 'recognises')\n\n"
("('CLAIM_CONTENTS', 'the need to involve the public and stakeholders in "
 'development of robots and provides a list of key design considerations '
 'including: Robots should not be designed primarily to kill humans;Humans '
 'remain responsible agents;It must be possible to find out who is responsible '
 'for any robot;Robots should be safe and fit for purpose;Robots should not be '
 'designed to be deceptive;The precautionary principle should be '
 'followed;Privacy should be built into the design;Users should not be '
 "discriminated against, nor forced to use a robot')\n"
 '\n')
"('SOURCE', 'The IEEE Standards Association')\n\n"
"('SOURCE', 'IEEE')\n\n"
("('CLAIM_CONTENTS', 'explicitly seeks to reposition robotics and AI as "
 'technologies for improving the human condition rather than simply vehicles '
 "for economic growth (Winfield, 2019a')\n"
 '\n')
"('SOURCE', 'IEEE')\n\n"
("('SOURCE', 'Panel for the Future of Science and Technology 68 Table 2: "
 "IEEE')\n"
 '\n')
"('CLAIM_VERB', 'establish')\n\n"
("('CLAIM_CONTENTS', 'a process for ethical design of Autonomous and "
 "Intelligent Systems')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('CLAIM_VERB', 'recognises')\n\n"
"('CLAIM_VERB', 'establish')\n\n"
("('CLAIM_CONTENTS', 'a baseline for metrics used to assess well-being factors "
 'that could be affected by autonomous systems, and for how human well-being '
 "could proactively be improved')\n"
 '\n')
"('CLAIM_VERB', 'establish')\n\n"
("('CLAIM_CONTENTS', 'how privacy terms are presented and how they could be "
 "read and accepted by machines')\n"
 '\n')
"('SOURCE', 'Canada')\n\n"
"('SOURCE', 'the European Commission')\n\n"
"('SOURCE', 'Russia')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
('(\'SOURCE\', "The European Commission\'s Communication on Artificial '
 'Intelligence")\n'
 '\n')
("('CLAIM_CONTENTS', 'nine months later with the presentation of a coordinated "
 "plan on AI (European Commission, 2018b')\n"
 '\n')
"('SOURCE', 'Commission')\n\n"
"('SOURCE', 'Guidelines')\n\n"
"('SOURCE', 'EU')\n\n"
"('CLAIM_VERB', 'released')\n\n"
("('CLAIM_CONTENTS', 'a further set of policy and investment guidelines for "
 "trustworthy AI (European Commission High-Level Expert Group on AI, 2019b')\n"
 '\n')
"('SOURCE', 'The Council of Europe')\n\n"
"('CLAIM_VERB', 'established')\n\n"
("('CLAIM_CONTENTS', 'an Ad Hoc Committee on Artificial Intelligence "
 "(CAHAI)')\n"
 '\n')
"('CLAIM_VERB', 'assess')\n\n"
('(\'CLAIM_CONTENTS\', "the potential elements of a legal framework for the '
 "development and application of AI, based on the Council's founding "
 'principles of human rights, democracy and the rule of law (Council of '
 'Europe, 2019a")\n'
 '\n')
"('SOURCE', 'Kayali')\n\n"
"('SOURCE', 'The European Commission')\n\n"
"('CLAIM_VERB', 'provides')\n\n"
("('CLAIM_CONTENTS', 'a unifying framework for AI development in the EU, but "
 "Member States are also required to develop their own national strategies')\n"
 '\n')
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'Sweden')\n\n"
"('SOURCE', 'The Danish Government')\n\n"
"('SOURCE', 'The Danish Government')\n\n"
"('CLAIM_VERB', 'establish')\n\n"
"('CLAIM_VERB', 'establish')\n\n"
"('SOURCE', 'Macron')\n\n"
"('SOURCE', 'Villani')\n\n"
("('CLAIM_CONTENTS', 'soon after in November 2018 (Die Bundesregierung, "
 "2018')\n"
 '\n')
"('SOURCE', 'Sweden')\n\n"
"('CLAIM_VERB', 'established')\n\n"
"('SOURCE', 'Swedish AI Council')\n\n"
"('SOURCE', 'CDEI')\n\n"
"('SOURCE', 'CDEI')\n\n"
"('CLAIM_VERB', 'assess')\n\n"
("('CLAIM_CONTENTS', 'the risks of AI, review regulatory and governance "
 'frameworks and advise the government and technology creators on best '
 'practice (UK Government Department for Digital, Culture, Media & Sport, '
 "2019')\n"
 '\n')
"('SOURCE', 'Austria')\n\n"
"('CLAIM_VERB', 'established')\n\n"
('(\'CLAIM_CONTENTS\', "a \'Robot Council\' to help the Government to develop '
 'a national AI Strategy (Austrian Council on Robotics and Artificial '
 'Intelligence, 2019")\n'
 '\n')
"('CLAIM_VERB', 'established')\n\n"
"('SOURCE', 'Italy')\n\n"
"('CLAIM_VERB', 'describes')\n\n"
("('CLAIM_CONTENTS', 'ethics as the first challenge to the successful "
 'implementation of AI, stating a need to uphold the principle that AI should '
 'be at the service of the citizen and to ensure equality by using technology '
 "to address universal needs')\n"
 '\n')
"('CLAIM_VERB', 'established')\n\n"
("('CLAIM_CONTENTS', 'composed of industry representatives, academics and "
 'other experts to help devise a policy for Malta that will focus on an '
 'ethical, transparent and socially-responsible AI while developing measures '
 'that garner foreign investment, which will include developing the skillset '
 "and infrastructure needed to support AI in Malta')\n"
 '\n')
"('CLAIM_VERB', 'released')\n\n"
"('SOURCE', 'the Digital Poland Foundation')\n\n"
"('SOURCE', 'Bershidski')\n\n"
"('SOURCE', 'Le Miere')\n\n"
"('SOURCE', 'the Russian Ministry of Defence')\n\n"
"('CLAIM_VERB', 'released')\n\n"
("('CLAIM_CONTENTS', 'a list of policy recommendations, which include creating "
 "a state system for AI education and a national centre for AI.')\n"
 '\n')
"('CLAIM_VERB', 'suggest')\n\n"
"('SOURCE', 'Putin')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'European Commission')\n\n"
"('CLAIM_VERB', 'reflected')\n\n"
('(\'CLAIM_CONTENTS\', "that citizens hold a generally positive view of these '
 'developments, viewing them as a positive addition to society, the economy, '
 'and citizens\' lives")\n'
 '\n')
"('CLAIM_VERB', 'showed')\n\n"
"('CLAIM_CONTENTS', 'that respondents were:')\n\n"
"('SOURCE', 'Canadian Institute For Advanced Research')\n\n"
"('CLAIM_VERB', 'established')\n\n"
("('CLAIM_CONTENTS', 'with four key goals, to: increase the number of AI "
 'researchers and graduates in Canada; establish centres of scientific '
 'excellence (in Edmonton, Montreal and Toronto); develop global thought '
 'leadership in the economic, ethical, policy and legal implications of AI; '
 "and support a national research community in AI.')\n"
 '\n')
"('CLAIM_VERB', 'publish')\n\n"
"('CLAIM_CONTENTS', 'their findings for both government and public.')\n\n"
"('SOURCE', 'Canadian Institute For Advanced Research')\n\n"
"('SOURCE', 'Trump')\n\n"
"('SOURCE', 'The White House')\n\n"
"('SOURCE', 'The White House')\n\n"
"('SOURCE', 'The American AI Initiative')\n\n"
"('SOURCE', 'The Department of Defence')\n\n"
"('SOURCE', 'US')\n\n"
"('CLAIM_VERB', '$')\n\n"
("('CLAIM_CONTENTS', '2.2 billion into developing a national AI strategy, as "
 "well as funding federal R&D.')\n"
 '\n')
"('CLAIM_VERB', 'establish')\n\n"
('(\'CLAIM_CONTENTS\', "a coordinated Federal initiative to accelerate '
 'research and development on artificial intelligence for the economic and '
 "national security of the United States' commits to establishing a National "
 'AI Coordination Office, create AI evaluation standards and fund 5 national '
 'AI research centres")\n'
 '\n')
"('SOURCE', 'the National Science Foundation')\n\n"
"('SOURCE', 'the Department of Energy')\n\n"
"('SOURCE', 'the National Artificial Intelligence Research')\n\n"
"('CLAIM_VERB', 'provides')\n\n"
"('SOURCE', 'the Chinese Government')\n\n"
"('CLAIM_VERB', 'released')\n\n"
('(\'CLAIM_CONTENTS\', "the \'Next Generation AI Development Plan\' in July '
 '2017")\n'
 '\n')
('(\'CLAIM_CONTENTS\', "the \'Three-Year Action Plan for Promoting Development '
 "of a New Generation Artificial Intelligence Industry', the strategy iterates "
 'four main goals, to: scale-up the development of key AI products (with a '
 'focus on intelligent vehicles, service robots, medical diagnosis and video '
 'image identification STOA | Panel for the Future of Science and Technology '
 '78 systems); significantly enhance core competencies in AI; deepen the '
 'development of smart manufacturing; and establish the foundation for an AI '
 'industry support system (New America, 2018")\n'
 '\n')
"('SOURCE', 'India')\n\n"
"('SOURCE', 'NITI Aayog')\n\n"
"('SOURCE', 'India')\n\n"
"('SOURCE', 'India')\n\n"
"('SOURCE', 'Taiwan')\n\n"
"('CLAIM_VERB', 'released')\n\n"
('(\'CLAIM_CONTENTS\', "an \'AI Action Plan\' in January 2018 (AI Taiwan, '
 '2018")\n'
 '\n')
"('CLAIM_VERB', 'provides')\n\n"
"('SOURCE', 'Malaysia')\n\n"
"('SOURCE', 'Abas')\n\n"
"('SOURCE', 'the Malaysia Digital Economy Corporation')\n\n"
'(\'SOURCE\', "Sri Lanka\'s")\n\n'
"('SOURCE', 'Dhammika Perera')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('SOURCE', 'the Computer Society')\n\n"
"('SOURCE', 'the United Arab Emirates')\n\n"
"('SOURCE', 'the Israel Innovation Authority')\n\n"
"('SOURCE', 'Israel Innovation Authority')\n\n"
"('CLAIM_VERB', 'recommended')\n\n"
('(\'CLAIM_CONTENTS\', "that Israel develop a national AI strategy \'shared by '
 'government, academia and industry")\n'
 '\n')
"('CLAIM_VERB', 'suggests')\n\n"
("('CLAIM_CONTENTS', 'this technology could solve some of the most pressing "
 'problems in Sub-Saharan Africa, from agricultural yields to providing secure '
 "financial services (Access Partnership, 2018')\n"
 '\n')
("('CLAIM_CONTENTS', 'that lack of government engagement to date has been a "
 'hindrance and encouraging African governments to take a proactive approach '
 "to AI policy')\n"
 '\n')
"('SOURCE', 'Kenya')\n\n"
"('SOURCE', 'the Ministry of Information and Communication')\n\n"
('(\'CLAIM_CONTENTS\', "a task force to put together a national strategy on AI '
 "and held a workshop in 2018 entitled 'National AI Strategy: Unlocking "
 'Tunisia\'s capabilities potential\' (ANPR, 2018")\n'
 '\n')
('(\'CLAIM_CONTENTS\', "governance framework to promote multi-sectorial '
 "dialogue; map the needs of industry; promote Mexico's international "
 'leadership in AI; publish recommendations for public consultation; and work '
 'both with experts and the public to achieve the continuity of these efforts '
 '(México Digital, 2018")\n'
 '\n')
"('SOURCE', 'the British Embassy')\n\n"
"('SOURCE', 'Oxford Insights')\n\n"
"('SOURCE', 'Mexico')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
"('SOURCE', 'Ovanessoff')\n\n"
"('SOURCE', 'Australasia Australia')\n\n"
"('SOURCE', 'Dawson')\n\n"
"('SOURCE', 'The AI Forum of New Zealand')\n\n"
"('SOURCE', 'STOA')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('CLAIM_VERB', 'establish')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'G7 Common Vision for the Future of AI')\n\n"
"('SOURCE', 'Charlevoix')\n\n"
"('CLAIM_VERB', 'andsupports')\n\n"
("('CLAIM_CONTENTS', 'economic growth.3.Support education, training and "
 're-skilling for the workforce.4.Support and involve underrepresented groups, '
 'including women and marginalisedindividuals, in the development and '
 'implementation of AI.Challenges to government adoption of AI The World '
 'Economic Forum has, through consultation with stakeholders, identified five '
 'major roadblocks to government adoption of AI: 1.Effective use of data - '
 'Lack of understanding of data infrastructure, not implementingdata '
 'governance processes (e.g. employing data officers and tools to efficiently '
 'accessdata).2.Data and AI skills - It is difficult for governments, which '
 'have smaller hiring budgetsthan many big companies, to attract candidates '
 'with the required skills to develop first-rate AI solutions.3.The AI '
 'ecosystem - There are many different companies operating in the AI market '
 "andit is rapidly changing.')\n"
 '\n')
"('CLAIM_VERB', 'established')\n\n"
"('SOURCE', 'Gerdon')\n\n"
"('CLAIM_VERB', 'initiatives')\n\n"
"('SOURCE', 'Sweden')\n\n"
"('CLAIM_VERB', 'aims')\n\n"
"('SOURCE', 'the Organisation for Economic Co-operation')\n\n"
"('CLAIM_VERB', 'agreed')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'States')\n\n"
"('SOURCE', 'Peru')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'G20')\n\n"
"('SOURCE', 'G20')\n\n"
"('SOURCE', 'United Nations')\n\n"
"('SOURCE', 'UN')\n\n"
"('SOURCE', 'Summits')\n\n"
"('CLAIM_VERB', 'held')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'UNICRI')\n\n"
"('CLAIM_VERB', 'launched')\n\n"
"('SOURCE', 'UNICRI')\n\n"
"('SOURCE', 'Microsoft')\n\n"
"('SOURCE', 'Google')\n\n"
"('SOURCE', 'Microsoft Bradford Smith')\n\n"
"('SOURCE', 'the Global AI Council')\n\n"
"('CLAIM_VERB', 'released')\n\n"
("('CLAIM_CONTENTS', 'a framework for developing a national AI strategy to "
 'guide governments that are yet to develop or are currently developing a '
 "national strategy for AI.')\n"
 '\n')
"('SOURCE', 'WEF')\n\n"
"('SOURCE', 'Vanian')\n\n"
"('SOURCE', 'Canada')\n\n"
"('SOURCE', 'Oxford Insights')\n\n"
"('CLAIM_VERB', 'evaluated')\n\n"
('(\'CLAIM_CONTENTS\', "the \'AI readiness\' of governments around the globe '
 'in 2019, using a range of data including not only the presence of a national '
 'AI strategy, but also data protection laws, statistics on AI startups and '
 'technology skills")\n'
 '\n')
"('SOURCE', 'States')\n\n"
"('CLAIM_VERB', 'agreed')\n\n"
"('SOURCE', 'Sweden')\n\n"
"('CLAIM_VERB', 'France')\n\n"
"('SOURCE', 'Canada')\n\n"
"('SOURCE', 'Australasia')\n\n"
('(\'CLAIM_CONTENTS\', "the ability of governments to capitalise on AI\'s '
 'potential in the coming years")\n'
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('CLAIM_VERB', 'establish')\n\n"
"('SOURCE', 'Germany')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'Taiwan')\n\n"
"('SOURCE', 'EU')\n\n"
"('CLAIM_VERB', '€')\n\n"
('(\'CLAIM_CONTENTS\', "70 million re-training scheme to help people gain '
 "digital skills and Germany has revealed a similar 'National Further Training "
 'Strategy\'.")\n'
 '\n')
"('SOURCE', 'India')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
"('CLAIM_VERB', 'allocate')\n\n"
"('CLAIM_CONTENTS', 'separate funding for it.')\n\n"
"('SOURCE', 'India')\n\n"
"('SOURCE', 'India')\n\n"
"('SOURCE', 'States')\n\n"
"('SOURCE', 'Sweden')\n\n"
"('CLAIM_VERB', 'states')\n\n"
('(\'CLAIM_CONTENTS\', "a need to develop partnerships and collaborations with '
 "other countries 'especially within the EU', while Denmark's strategy also "
 'emphasises close cooperation with other European countries")\n'
 '\n')
"('SOURCE', 'India')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'the Organisation for Economic Co-operation and Development')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'OECD')\n\n"
"('CLAIM_CONTENTS', 'by 42 countries')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'G20')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'G20')\n\n"
"('SOURCE', 'The OECD Principles')\n\n"
"('SOURCE', 'the European Commission')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'OECD')\n\n"
"('CLAIM_VERB', 'suggest')\n\n"
("('CLAIM_CONTENTS', 'ways to achieve this, nor does it mention any specific "
 "environmental challenges to be considered')\n"
 '\n')
"('SOURCE', 'The EU Communication on AI')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'EU')\n\n"
"('CLAIM_VERB', 'state')\n\n"
('(\'CLAIM_CONTENTS\', "that such effects must \'be carefully monitored and '
 "considered' and that AI interacting with humans must clearly signal that its "
 'social interaction is simulated.")\n'
 '\n')
"('SOURCE', 'OECD')\n\n"
"('CLAIM_VERB', 'states')\n\n"
('(\'CLAIM_CONTENTS\', "that AI should be developed in a way that reduces '
 '\'economic, social, gender and other inequalities")\n'
 '\n')
"('SOURCE', 'OECD')\n\n"
"('CLAIM_VERB', 'states')\n\n"
("('CLAIM_CONTENTS', 'that AI systems should respect diversity and include "
 'safeguards to ensure a fair society, however detail on how this can be '
 "achieved is lacking')\n"
 '\n')
"('SOURCE', 'EU')\n\n"
"('CLAIM_VERB', 'state')\n\n"
("('CLAIM_CONTENTS', 'that AI should be trained on data which is "
 "representative of different groups in order to prevent biased outputs')\n"
 '\n')
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'OECD')\n\n"
"('CLAIM_VERB', 'state')\n\n"
('(\'CLAIM_CONTENTS\', "that AI systems should serve to maintain democracy and '
 "not undermine 'democratic processes, human deliberation or democratic voting "
 'systems")\n'
 '\n')
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'OECD')\n\n"
"('CLAIM_VERB', 'stated')\n\n"
"('SOURCE', 'OECD')\n\n"
"('CLAIM_VERB', 'states')\n\n"
('(\'CLAIM_CONTENTS\', "that \'organisations and individuals developing, '
 'deploying or operating AI systems should be held accountable for their '
 'proper functioning\' (OECD, 2019a")\n'
 '\n')
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'OECD')\n\n"
"('CLAIM_VERB', 'states')\n\n"
('(\'CLAIM_CONTENTS\', "that AI systems should ensure a \'fair and just '
 'society")\n'
 '\n')
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'OECD')\n\n"
"('CLAIM_VERB', 'unaddressed')\n\n"
"('SOURCE', 'G7')\n\n"
"('SOURCE', 'Reuters')\n\n"
"('CLAIM_VERB', 'suggests')\n\n"
"('CLAIM_CONTENTS', 'that regulatory changes in this regard are afoot')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('CLAIM_VERB', 'rapidly')\n\n"
("('CLAIM_CONTENTS', 'developing technology, but not all countries understand "
 "ethics in the same way.')\n"
 '\n')
"('CLAIM_VERB', 'shows')\n\n"
("('CLAIM_CONTENTS', 'that the vast majority of ethical issues identified here "
 'are also addressed in some form by at least one of the current international '
 'frameworks; the EU Communication (supplemented by separate ethics '
 "guidelines) and the OECD Principles on AI')\n"
 '\n')
"('CLAIM_VERB', 'show')\n\n"
'(\'SOURCE\', "the Accountability Office\'s Technology Assessment Unit")\n\n'
"('SOURCE', 'India')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'Allen')\n\n"
('(\'CLAIM_CONTENTS\', "programming moral rules and decisions into artificial '
 'agents, such as \'thou shalt not kill")\n'
 '\n')
"('CLAIM_VERB', 'distinguish')\n\n"
"('CLAIM_CONTENTS', 'between moral and immoral behaviours')\n\n"
"('CLAIM_VERB', 'demonstrate')\n\n"
"('CLAIM_VERB', 'unintended')\n\n"
"('CLAIM_VERB', 'behaviour')\n\n"
('(\'CLAIM_CONTENTS\', "that leads to the most happiness\', the machine may '
 'discover that it can more quickly reach its goal of maximising happiness by '
 "first increasing its own learning efficiency, 'temporarily' shifting away "
 'from the original goal.")\n'
 '\n')
"('CLAIM_VERB', 'behaviours')\n\n"
("('CLAIM_CONTENTS', 'that temporarily reduce happiness, if these behaviours "
 "were to ultimately help it achieve its goal.')\n"
 '\n')
"('CLAIM_VERB', 'paragon')\n\n"
"('CLAIM_VERB', 'rules')\n\n"
"('SOURCE', 'Bentham')\n\n"
"('CLAIM_VERB', 'proposed')\n\n"
("('CLAIM_CONTENTS', 'that a moral agent should aim to maximise the total "
 "happiness of a population of people.')\n"
 '\n')
"('CLAIM_VERB', 'argues')\n\n"
("('CLAIM_CONTENTS', 'that actions should be judged not on the basis of their "
 "expected outcomes, but on what people do')\n"
 '\n')
"('CLAIM_CONTENTS', 'that it produced good consequences')\n\n"
"('SOURCE', 'Bogosian')\n\n"
"('CLAIM_VERB', 'holds')\n\n"
('(\'CLAIM_CONTENTS\', "that no tradeoff is permissible, there is no obvious '
 '\'halfway point\' where the competing principles can meet")\n'
 '\n')
"('CLAIM_VERB', 'states')\n\n"
('(\'CLAIM_CONTENTS\', "that if doing something morally good has a morally bad '
 "side-effect, it's ethically okay to do it providing that the bad side-effect "
 'wasn\'t intended.")\n'
 '\n')
('(\'CLAIM_CONTENTS\', "that maximised a \'good outcome\', an artificial agent '
 'would need to identify all possible consequences of a decision, from all '
 "parties' perspectives, before making a judgement about which consequence is "
 'preferable")\n'
 '\n')
"('SOURCE', 'Greene')\n\n"
"('SOURCE', 'Bogosian')\n\n"
"('CLAIM_VERB', 'argues')\n\n"
("('CLAIM_CONTENTS', 'that instead, we should design machines to be "
 "fundamentally uncertain about morality')\n"
 '\n')
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'AI4All')\n\n"
"('SOURCE', 'AI Now Report')\n\n"
"('SOURCE', 'New York University')\n\n"
"('SOURCE', 'G')\n\n"
"('SOURCE', 'G.')\n\n"
"('SOURCE', 'Anderson')\n\n"
"('SOURCE', 'Santa Monica')\n\n"
"('SOURCE', 'Russia')\n\n"
"('SOURCE', 'Asaro')\n\n"
"('SOURCE', 'Banning Autonomous Weapon Systems: Human Rights')\n\n"
"('SOURCE', 'European Research Studies Journal')\n\n"
"('SOURCE', 'The Digital Economy: Opening Up The Conversation.')\n\n"
"('SOURCE', 'Australia')\n\n"
"('SOURCE', 'Tech Future')\n\n"
"('SOURCE', 'The History and Future of Workplace Automation')\n\n"
"('SOURCE', 'Addison Lee')\n\n"
"('SOURCE', 'S.')\n\n"
"('SOURCE', 'The Washington Post')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'L')\n\n"
"('SOURCE', 'Elon Musk')\n\n"
"('CLAIM_VERB', 'warns')\n\n"
"('CLAIM_CONTENTS', 'battle for AI supremacy will spark Third World War')\n\n"
"('SOURCE', 'Bentham')\n\n"
"('SOURCE', 'J.')\n\n"
"('SOURCE', 'Strufe')\n\n"
"('SOURCE', 'WWW')\n\n"
"('SOURCE', 'Bogosian')\n\n"
"('SOURCE', 'J.and Arkin')\n\n"
"('SOURCE', 'R.C.')\n\n"
"('SOURCE', 'Working Paper: Project on Computational Propaganda')\n\n"
"('SOURCE', 'Oxford')\n\n"
"('SOURCE', 'The Second Machine Age: Work, Progress')\n\n"
"('SOURCE', 'W. W. Norton & Company')\n\n"
"('SOURCE', 'Bryson')\n\n"
"('SOURCE', 'Bryson')\n\n"
"('SOURCE', 'T.')\n\n"
"('SOURCE', 'Robert Mercer: The big data billionaire')\n\n"
"('SOURCE', 'Canadian Institute For Advanced Research')\n\n"
"('SOURCE', 'CDEI')\n\n"
"('SOURCE', 'The Centre for Data Ethics and Innovation')\n\n"
"('SOURCE', 'CDEI')\n\n"
"('SOURCE', 'The New Yorker')\n\n"
"('SOURCE', 'The Atlantic Magazine')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 96')\n\n"
"('SOURCE', 'Washington Law Review')\n\n"
"('SOURCE', 'CNN')\n\n"
"('SOURCE', 'Swiss')\n\n"
"('SOURCE', 'Canada')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('CLAIM_VERB', 'showed')\n\n"
"('CLAIM_CONTENTS', 'bias against women')\n\n"
"('SOURCE', 'Scowcroft')\n\n"
'(\'SOURCE\', "The Federal Government\'s Artificial Intelligence Strategy")\n\n'
"('SOURCE', 'Strategie Künstliche Intelligenz')\n\n"
"('SOURCE', 'T.')\n\n"
"('SOURCE', 'the European Parliament')\n\n"
"('SOURCE', 'the European Council')\n\n"
"('SOURCE', 'the European Economic and Social Committee')\n\n"
"('SOURCE', 'the European Parliament')\n\n"
"('SOURCE', 'the European Council')\n\n"
"('SOURCE', 'the European Economic and Social Committee')\n\n"
("('SOURCE', 'Panel for the Future of Science and Technology 98 European "
 "Commission')\n"
 '\n')
"('SOURCE', 'EU')\n\n"
"('SOURCE', 'States')\n\n"
"('SOURCE', 'Oxford Legal Studies Research Paper')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Floridi')\n\n"
"('CLAIM_VERB', 'paternalism')\n\n"
"('SOURCE', 'Oxford')\n\n"
"('SOURCE', 'Oxford University Press')\n\n"
"('SOURCE', 'Ford')\n\n"
("('SOURCE', 'The Lights in the Tunnel: Automation, Accelerating Technology')\n"
 '\n')
"('SOURCE', 'China')\n\n"
"('SOURCE', 'The Future of Employment: How Susceptible Are Jobs')\n\n"
"('SOURCE', 'G7 Canadian')\n\n"
"('SOURCE', 'G20')\n\n"
"('SOURCE', 'Gibbs')\n\n"
"('SOURCE', 'Tesla Model S')\n\n"
"('SOURCE', 'Gillespie')\n\n"
"('SOURCE', 'MA: MIT Press')\n\n"
"('SOURCE', 'O.')\n\n"
("('SOURCE', 'Panel for the Future of Science and Technology 100 Government "
 "Offices')\n"
 '\n')
"('SOURCE', 'Sweden')\n\n"
"('SOURCE', 'Sommerville')\n\n"
"('CLAIM_VERB', 'unpublished')\n\n"
"('SOURCE', 'Hadfield-Menell')\n\n"
"('SOURCE', 'Somer')\n\n"
"('SOURCE', 'Osula')\n\n"
"('SOURCE', 'T.')\n\n"
"('SOURCE', 'Dublin')\n\n"
"('SOURCE', 'G.')\n\n"
"('SOURCE', 'The Criminal Liability of Artificial Intelligence Entities')\n\n"
"('SOURCE', 'Van Hoboken')\n\n"
"('SOURCE', 'California')\n\n"
"('SOURCE', 'Google')\n\n"
"('SOURCE', 'IBM')\n\n"
"('SOURCE', 'Microsoft')\n\n"
"('SOURCE', 'Guardian')\n\n"
"('SOURCE', 'The New York Times')\n\n"
"('SOURCE', 'Xinjiang')\n\n"
"('SOURCE', 'IEEE')\n\n"
"('SOURCE', 'Babiak')\n\n"
"('SOURCE', 'United Nations Activities on Artificial Intelligence')\n\n"
"('SOURCE', 'New York Times')\n\n"
"('SOURCE', 'Israel Innovation Authority')\n\n"
"('SOURCE', 'The Energy Prosumer')\n\n"
"('SOURCE', 'Axinn')\n\n"
"('SOURCE', 'The Morality of Autonomous Robots')\n\n"
"('SOURCE', 'L.')\n\n"
"('SOURCE', 'Next European Commission')\n\n"
"('SOURCE', 'Kenya Govt')\n\n"
"('SOURCE', 'Bitange Ndemo')\n\n"
"('SOURCE', 'Khakurel')\n\n"
"('SOURCE', 'J.,Penzenstadler')\n\n"
"('SOURCE', 'Porras')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 102')\n\n"
"('SOURCE', 'Taddeo')\n\n"
"('SOURCE', 'Sci Eng Ethics')\n\n"
"('SOURCE', 'Kingston')\n\n"
"('SOURCE', 'The World Economic Forum')\n\n"
"('SOURCE', 'Kroll')\n\n"
"('SOURCE', 'MIT')\n\n"
"('SOURCE', 'Samek')\n\n"
"('SOURCE', 'K.R.')\n\n"
"('SOURCE', 'LaRosa')\n\n"
"('SOURCE', 'BBC Business News')\n\n"
"('SOURCE', 'Russia')\n\n"
"('SOURCE', 'Tech Times')\n\n"
"('CLAIM_CONTENTS', 'that killed woman in Arizona')\n\n"
"('SOURCE', 'Honolulu')\n\n"
"('SOURCE', 'Williams')\n\n"
"('SOURCE', 'Zuckerberg')\n\n"
"('SOURCE', 'Killer Robots and Human Dignity')\n\n"
"('SOURCE', 'Honolulu')\n\n"
"('SOURCE', 'Krispy Kreme')\n\n"
"('SOURCE', 'Lin')\n\n"
"('SOURCE', 'Emory Law Journal')\n\n"
"('SOURCE', 'Lin')\n\n"
"('SOURCE', 'MIT Press')\n\n"
"('SOURCE', 'Miller')\n\n"
"('SOURCE', 'Lee Sedol')\n\n"
"('SOURCE', 'Jacques Mattheij: Technology')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 104 Mbadiwe')\n\n"
"('SOURCE', 'T.')\n\n"
"('SOURCE', 'MA: MIT Press')\n\n"
"('SOURCE', 'Rensselaer Polytechnic Institute')\n\n"
"('SOURCE', 'Millar')\n\n"
"('CLAIM_VERB', 'allows')\n\n"
"('SOURCE', 'The National Artificial Intelligence Research')\n\n"
"('SOURCE', 'NTSB')\n\n"
"('SOURCE', 'Test Vehicle')\n\n"
"('SOURCE', 'Miller')\n\n"
"('SOURCE', 'NITI Aayog')\n\n"
("('SOURCE', 'the European Commission on Artificial Intelligence and "
 "Robotics')\n"
 '\n')
"('SOURCE', 'M.S.')\n\n"
"('SOURCE', 'T.')\n\n"
"('SOURCE', 'Russia')\n\n"
"('SOURCE', 'J.')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'OECD')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'L. & Armstrong')\n\n"
"('SOURCE', 'Ovanessoff')\n\n"
"('SOURCE', 'Oxford Insights')\n\n"
("('SOURCE', 'The Black Box Society: The Secret Algorithms that Control Money "
 "and Information')\n"
 '\n')
"('SOURCE', 'MA')\n\n"
"('SOURCE', 'Harvard University Press')\n\n"
"('SOURCE', 'Brexit')\n\n"
"('SOURCE', 'The National Bureau of Economic Research')\n\n"
"('SOURCE', 'State')\n\n"
"('SOURCE', 'MacronLeaks')\n\n"
"('SOURCE', 'Clinton')\n\n"
"('SOURCE', 'Guardian')\n\n"
("('CLAIM_VERB', "
 "'https://www.theguardian.com/society/2019/feb/11/robots-and-ai-to-give-doctors-more-time-with-patients-says-report')\n"
 '\n')
"('SOURCE', 'ProPublica')\n\n"
"('SOURCE', 'I.')\n\n"
"('SOURCE', 'Saint Paul')\n\n"
"('SOURCE', 'Reuters')\n\n"
"('SOURCE', 'G7')\n\n"
"('CLAIM_VERB', 'urges')\n\n"
("('CLAIM_CONTENTS', 'tight regulations for digital currencies, agrees to tax "
 "digital giants locally')\n"
 '\n')
"('SOURCE', 'M.O.')\n\n"
"('SOURCE', 'Harrison')\n\n"
("('CLAIM_CONTENTS', 'the matrix: A virtual world approach to safely "
 "interruptable autonomous systems')\n"
 '\n')
"('SOURCE', 'Roberts')\n\n"
"('SOURCE', 'SAE International')\n\n"
"('SOURCE', 'Arizona')\n\n"
"('SOURCE', 'I.')\n\n"
"('SOURCE', 'I.')\n\n"
"('SOURCE', 'Guardian')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 108 Sathe G.')\n\n"
"('SOURCE', 'India')\n\n"
"('SOURCE', 'G.')\n\n"
"('SOURCE', 'J. L. & Tech')\n\n"
"('SOURCE', 'MIT Press')\n\n"
"('SOURCE', 'M.N.')\n\n"
"('SOURCE', 'Cambridge University Press')\n\n"
"('SOURCE', 'The Future of Work')\n\n"
"('SOURCE', 'Goodman')\n\n"
"('SOURCE', 'N.')\n\n"
"('SOURCE', 'Arizona')\n\n"
"('SOURCE', 'Reuters News')\n\n"
"('SOURCE', 'Microsoft')\n\n"
"('SOURCE', 'Swedish AI Council')\n\n"
"('SOURCE', 'The Danish Government')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology 110')\n\n"
"('SOURCE', 'The Danish Government')\n\n"
"('SOURCE', 'The Future of Life Institute')\n\n"
"('SOURCE', 'The Future of Life Institute')\n\n"
("('SOURCE', 'Background: Benefits and Risks of Artificial "
 "Intelligence.[online')\n"
 '\n')
"('SOURCE', 'The Future Society')\n\n"
"('SOURCE', 'The Institute of Electrical and Electronics Engineers')\n\n"
"('SOURCE', 'The Institute of Electrical and Electronics Engineers')\n\n"
"('SOURCE', 'The Institute for Ethical AI & Machine Learning')\n\n"
"('SOURCE', 'The Partnership on AI')\n\n"
"('SOURCE', 'The White House')\n\n"
"('SOURCE', 'The White House')\n\n"
"('SOURCE', 'The White House')\n\n"
"('CLAIM_VERB', 'program')\n\n"
"('CLAIM_CONTENTS', 'that can tell whether you may go blind')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Guardian')\n\n"
"('SOURCE', 'TUM')\n\n"
"('SOURCE', 'New Research Institute for Ethics in Artificial Intelligence')\n\n"
"('SOURCE', 'UCL')\n\n"
"('SOURCE', 'UNICRI')\n\n"
"('SOURCE', 'UNICRI Centre for Artificial Intelligence and Robotics')\n\n"
"('SOURCE', 'The Future of Work: Jobs')\n\n"
"('SOURCE', 'Université de Montréal')\n\n"
"('SOURCE', 'J.')\n\n"
"('SOURCE', 'Panel for the Future of Science and Technology')\n\n"
"('SOURCE', 'L.')\n\n"
"('SOURCE', 'Google')\n\n"
"('SOURCE', 'Working Partnerships USA')\n\n"
"('SOURCE', 'A.R.')\n\n"
("('SOURCE', 'An Autonomous Architecture that Protects the Right to Privacy')\n"
 '\n')
"('SOURCE', 'Oxford University Press')\n\n"
"('SOURCE', 'W. H. Freeman & Co. Wellman')\n\n"
"('SOURCE', 'The Future of Work: Robots')\n\n"
"('SOURCE', 'Williams')\n\n"
"('SOURCE', 'R.')\n\n"
"('SOURCE', 'Tynan')\n\n"
"('SOURCE', 'Tesla')\n\n"
"('SOURCE', 'Yatskar')\n\n"
"('SOURCE', 'Zou')\n\n"
"('SOURCE', 'L.')\n\n"
"('SOURCE', 'European Parliamentary Research Service')\n\n"
"('SOURCE', 'the European Parliament')\n\n"
